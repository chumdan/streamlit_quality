import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
import xgboost as xgb
from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler
import shap
import plotly.express as px
import plotly.graph_objects as go
import io
import sys
import traceback
from scipy import stats
import itertools

# í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams['font.family'] = 'Malgun Gothic'
plt.rcParams['axes.unicode_minus'] = False

# íŒŒì¼ ìƒë‹¨ì— ì¶”ê°€ (ê³µí†µ ê·¸ë˜í”„ ì„¤ì •)
def display_plot_centered(fig, width_pct=60):
    """ê·¸ë˜í”„ë¥¼ ì¤‘ì•™ì— í‘œì‹œí•˜ëŠ” í—¬í¼ í•¨ìˆ˜"""
    left_margin = (100 - width_pct) // 2
    right_margin = 100 - width_pct - left_margin
    cols = st.columns([left_margin, width_pct, right_margin])
    with cols[1]:
        st.pyplot(fig)

def display_plotly_centered(fig, width_pct=60):
    """Plotly ê·¸ë˜í”„ë¥¼ ì¤‘ì•™ì— í‘œì‹œí•˜ëŠ” í—¬í¼ í•¨ìˆ˜"""
    left_margin = (100 - width_pct) // 2
    right_margin = 100 - width_pct - left_margin
    cols = st.columns([left_margin, width_pct, right_margin])
    with cols[1]:
        st.plotly_chart(fig, use_container_width=True)

st.title("4. ì‹œë®¬ë ˆì´ì…˜")

# ì‹œë®¬ë ˆì´ì…˜ ê°œë… ì„¤ëª… ì¶”ê°€
with st.expander("ğŸ“š ì˜ˆì¸¡ ì‹œë®¬ë ˆì´ì…˜ì´ë€?"):
    st.markdown("""
    ### ì˜ˆì¸¡ ì‹œë®¬ë ˆì´ì…˜(Predictive Simulation)
    ì˜ˆì¸¡ ì‹œë®¬ë ˆì´ì…˜ì€ ê³¼ê±° ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•™ìŠµëœ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ë³€ìˆ˜ë“¤ì˜ ë‹¤ì–‘í•œ ê°’ ì¡°í•©ì— ë”°ë¥¸ ê²°ê³¼ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ê³¼ì •ì…ë‹ˆë‹¤.
    
    ### ì´ í˜ì´ì§€ì˜ ê¸°ëŠ¥
    
    **1. ë°ì´í„° ì¤€ë¹„**
    - CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì—¬ ë¶„ì„ ë°ì´í„°ë¥¼ ì¤€ë¹„í•©ë‹ˆë‹¤.
    - ì˜ˆì¸¡í•˜ê³ ì í•˜ëŠ” íƒ€ê²Ÿ ë³€ìˆ˜ë¥¼ ì„ íƒí•©ë‹ˆë‹¤.
    - ì´ìƒì¹˜ ì œê±°ì™€ ë°ì´í„° ìŠ¤ì¼€ì¼ë§ ì˜µì…˜ì„ ì œê³µí•©ë‹ˆë‹¤.
    
    **2. ìƒê´€ê´€ê³„ ë¶„ì„**
    - íƒ€ê²Ÿ ë³€ìˆ˜ì™€ ìƒê´€ê´€ê³„ê°€ ë†’ì€ ì£¼ìš” ë³€ìˆ˜ë“¤ì„ ì‹ë³„í•©ë‹ˆë‹¤.
    - ì´ ë³€ìˆ˜ë“¤ì€ ì˜ˆì¸¡ ëª¨ë¸ì— ì¤‘ìš”í•œ ì¸ìê°€ ë©ë‹ˆë‹¤.
    - ìƒê´€ê´€ê³„ ì‹œê°í™”ë¥¼ í†µí•´ ë³€ìˆ˜ ê°„ ê´€ê³„ë¥¼ ì‰½ê²Œ íŒŒì•…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    
    **3. ëª¨ë¸ í›ˆë ¨**
    - ì„¸ ê°€ì§€ ëª¨ë¸ ì˜µì…˜ ì œê³µ:
      - **ì„ í˜• íšŒê·€**: ë³€ìˆ˜ ê°„ ì„ í˜• ê´€ê³„ë¥¼ ë¶„ì„í•˜ê³  í•´ì„ì´ ìš©ì´í•©ë‹ˆë‹¤.
      - **RandomForest**: ë¹„ì„ í˜• ê´€ê³„ë„ í¬ì°©í•˜ë©° ê³¼ì í•©ì— ê°•í•©ë‹ˆë‹¤.
      - **XGBoost**: ë†’ì€ ì˜ˆì¸¡ ì •í™•ë„ë¥¼ ì œê³µí•˜ëŠ” ê³ ì„±ëŠ¥ ì•Œê³ ë¦¬ì¦˜ì…ë‹ˆë‹¤.
    - ëª¨ë¸ ì„±ëŠ¥ í‰ê°€(RÂ², RMSE) ë° ë³€ìˆ˜ ì¤‘ìš”ë„ ë¶„ì„ì„ ì œê³µí•©ë‹ˆë‹¤.
    - íšŒê·€ ëª¨ë¸ì˜ ê²½ìš° ìƒì„¸í•œ í†µê³„ ë¶„ì„ ê²°ê³¼ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
    
    **4. ì˜ˆì¸¡ ì‹œë®¬ë ˆì´ì…˜**
    ë‘ ê°€ì§€ ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œë¥¼ ì œê³µí•©ë‹ˆë‹¤:
    
    **A. ìˆ˜ë™ ì‹œë®¬ë ˆì´ì…˜**
    - ì£¼ìš” ë³€ìˆ˜ë“¤ì˜ ê°’ì„ ì§ì ‘ ì¡°ì •í•˜ë©° ê²°ê³¼ ë³€í™”ë¥¼ í™•ì¸
    - ê° ë³€ìˆ˜ì˜ í‰ê· ê³¼ í‘œì¤€í¸ì°¨ ì •ë³´ ì œê³µ
    - ì‹¤ì‹œê°„ìœ¼ë¡œ ì˜ˆì¸¡ ê²°ê³¼ í™•ì¸ ê°€ëŠ¥
    
    **B. ìµœì í™” ì‹œë®¬ë ˆì´ì…˜**
    - ëª©í‘œê°’ì„ ì„¤ì •í•˜ê³  ìë™ìœ¼ë¡œ ìµœì ì˜ ë³€ìˆ˜ ì¡°í•©ì„ íƒìƒ‰
    - ëœë¤ ì„œì¹˜ ì•Œê³ ë¦¬ì¦˜ì„ í†µí•œ íš¨ìœ¨ì ì¸ ìµœì í™”
    - ë³€ìˆ˜ë³„ íƒìƒ‰ ë²”ìœ„ ì„¤ì • ê°€ëŠ¥
    - ìµœì í™” ì§„í–‰ ìƒí™©ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ í™•ì¸
    
    ### í™œìš© ë°©ë²•
    
    - **ê³µì • ìµœì í™”**: ì›í•˜ëŠ” ê²°ê³¼ë¥¼ ì–»ê¸° ìœ„í•œ ìµœì ì˜ ë³€ìˆ˜ ì¡°í•©ì„ ì°¾ìŠµë‹ˆë‹¤.
    - **ë¯¼ê°ë„ ë¶„ì„**: ì–´ë–¤ ë³€ìˆ˜ê°€ ê²°ê³¼ì— ê°€ì¥ í° ì˜í–¥ì„ ë¯¸ì¹˜ëŠ”ì§€ íŒŒì•…í•©ë‹ˆë‹¤.
    - **í’ˆì§ˆ ì˜ˆì¸¡**: íŠ¹ì • ì¡°ê±´ì—ì„œ ì œí’ˆ í’ˆì§ˆì´ ì–´ë–»ê²Œ ë³€í™”í• ì§€ ì˜ˆì¸¡í•©ë‹ˆë‹¤.
    - **ë¶ˆëŸ‰ë¥  ê°ì†Œ**: ë¶ˆëŸ‰ ë°œìƒ ê°€ëŠ¥ì„±ì´ ë†’ì€ ì¡°ê±´ì„ ì‚¬ì „ì— ì‹ë³„í•˜ì—¬ ì˜ˆë°©í•©ë‹ˆë‹¤.
    - **ë¹„ìš© ì ˆê°**: ì¬ë£Œ ë° ì—ë„ˆì§€ ì†Œë¹„ë¥¼ ìµœì í™”í•˜ì—¬ ë¹„ìš©ì„ ì ˆê°í•©ë‹ˆë‹¤.
    - **ê°€ì„¤ ê²€ì¦**: íŠ¹ì • ë³€ìˆ˜ ì¡°ì •ì´ ê²°ê³¼ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ì‚¬ì „ ê²€ì¦í•©ë‹ˆë‹¤.
    
    ### ë°ì´í„° ì „ì²˜ë¦¬ ì˜µì…˜
    
    **1. ì´ìƒì¹˜ ì²˜ë¦¬**
    - Z-ì ìˆ˜ ë˜ëŠ” IQR ë°©ë²•ì„ í†µí•œ ì´ìƒì¹˜ ì œê±°
    - ì´ìƒì¹˜ ì œê±° ê¸°ì¤€ ì¡°ì • ê°€ëŠ¥
    
    **2. ë°ì´í„° ìŠ¤ì¼€ì¼ë§**
    - í‘œì¤€í™”(StandardScaler): í‰ê·  0, í‘œì¤€í¸ì°¨ 1ë¡œ ë³€í™˜
    - ë¡œë²„ìŠ¤íŠ¸ ìŠ¤ì¼€ì¼ë§(RobustScaler): ì´ìƒì¹˜ì— ê°•ê±´í•œ ìŠ¤ì¼€ì¼ë§
    - ì •ê·œí™”(MinMaxScaler): 0~1 ë²”ìœ„ë¡œ ë³€í™˜
    
    ### ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ ì„¤ëª…
    
    **1. ì„ í˜• íšŒê·€**
    - ë³€ìˆ˜ ê°„ ì„ í˜• ê´€ê³„ë¥¼ ëª¨ë¸ë§
    - íšŒê·€ ê³„ìˆ˜ë¥¼ í†µí•œ ì§ê´€ì ì¸ í•´ì„ ê°€ëŠ¥
    - ì •ê·œì„±, ì„ í˜•ì„±, ë“±ë¶„ì‚°ì„± ê²€ì • ì œê³µ
    
    **2. RandomForest(ëœë¤ í¬ë ˆìŠ¤íŠ¸)**
    - ì—¬ëŸ¬ ì˜ì‚¬ê²°ì • íŠ¸ë¦¬ì˜ ì•™ìƒë¸” ëª¨ë¸
    - ë‹¤ì–‘í•œ ë°ì´í„° íƒ€ì…ì— ì ìš© ê°€ëŠ¥
    - ê³¼ì í•©ì— ê°•í•˜ê³  ë³€ìˆ˜ ê°„ ìƒí˜¸ì‘ìš©ì„ ì˜ í¬ì°©
    
    **3. XGBoost**
    - ê·¸ë˜ë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ… ê¸°ë°˜ì˜ ê³ ì„±ëŠ¥ ì•Œê³ ë¦¬ì¦˜
    - ì¼ë°˜ì ìœ¼ë¡œ ë” ë†’ì€ ì˜ˆì¸¡ ì •í™•ë„
    - ë³€ìˆ˜ ì¤‘ìš”ë„ ë° í•´ì„ ê°€ëŠ¥
    """)

# íŒŒì¼ ì—…ë¡œë“œ ì˜ì—­
st.write("### ë°ì´í„° ì—…ë¡œë“œ")
uploaded_file = st.file_uploader("ì˜ˆì¸¡ ëª¨ë¸ë§ì„ ìœ„í•œ CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=['csv'])

# ë°ì´í„° ë¡œë“œ
data = None
if uploaded_file is not None:
    try:
        # íŒŒì¼ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸° (ë¬¸ì œ ì§„ë‹¨ìš©)
        file_bytes = uploaded_file.getvalue()
        try:
            preview_text = file_bytes[:1000].decode('utf-8')
        except UnicodeDecodeError:
            try:
                preview_text = file_bytes[:1000].decode('cp949')
            except UnicodeDecodeError:
                preview_text = "ì¸ì½”ë”© ë¬¸ì œë¡œ ë¯¸ë¦¬ë³´ê¸°ë¥¼ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        # êµ¬ë¶„ì ì„ íƒ ì˜µì…˜ ì¶”ê°€
        st.write("#### íŒŒì¼ ë¯¸ë¦¬ë³´ê¸°:")
        st.text(preview_text)
        
        delimiter_option = st.selectbox(
            "CSV êµ¬ë¶„ì ì„ íƒ:",
            options=[',', ';', '\t', '|'],
            index=0,
            format_func=lambda x: {',' : 'ì‰¼í‘œ(,)', ';' : 'ì„¸ë¯¸ì½œë¡ (;)', '\t': 'íƒ­(\\t)', '|': 'íŒŒì´í”„(|)'}[x]
        )
        
        # ë‹¤ì–‘í•œ ì¸ì½”ë”© ì‹œë„
        for encoding in ['utf-8', 'euc-kr', 'cp949']:
            try:
                # íŒŒì¼ í¬ì¸í„° ìœ„ì¹˜ ì´ˆê¸°í™”
                uploaded_file.seek(0)
                data = pd.read_csv(uploaded_file, encoding=encoding, delimiter=delimiter_option)
                if len(data.columns) <= 1 and data.columns[0].count(',') > 3:  # êµ¬ë¶„ì ê°ì§€ ë¬¸ì œì¸ ê²½ìš°
                    st.warning("êµ¬ë¶„ì ë¬¸ì œê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ êµ¬ë¶„ìë¥¼ ì„ íƒí•´ë³´ì„¸ìš”.")
                    data = None
                    continue
                break
            except Exception as e:
                continue
        
        if data is not None and len(data.columns) > 1:
            st.success(f"íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ! ë°ì´í„° í¬ê¸°: {data.shape[0]}í–‰ x {data.shape[1]}ì—´")
            
            # ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° í‘œì‹œ
            st.write("#### ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°:")
            st.dataframe(data.head())
        else:
            st.error("íŒŒì¼ì„ ì½ëŠ” ë° ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ êµ¬ë¶„ìë¥¼ ì„ íƒí•˜ê±°ë‚˜ íŒŒì¼ í˜•ì‹ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
            st.stop()
    except Exception as e:
        st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
        st.stop()

if data is not None:
    # íƒ€ê¹ƒ ë³€ìˆ˜ ì„ íƒ
    st.write("### ë³€ìˆ˜ ì„ íƒ")
    
    # ìˆ˜ì¹˜í˜• ë³€ìˆ˜ë§Œ ì¶”ì¶œ
    numeric_cols = data.select_dtypes(include=[np.number]).columns.tolist()
    
    if not numeric_cols:
        st.warning("ìˆ˜ì¹˜í˜• ë°ì´í„° ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. ë°ì´í„° íƒ€ì…ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        # ëª¨ë“  ì»¬ëŸ¼ì„ ë¬¸ìì—´ì—ì„œ ìˆ«ìë¡œ ë³€í™˜ ì‹œë„
        for col in data.columns:
            try:
                data[col] = pd.to_numeric(data[col])
                numeric_cols.append(col)
            except:
                pass
        
        if not numeric_cols:
            st.error("ë³€í™˜ ê°€ëŠ¥í•œ ìˆ˜ì¹˜í˜• ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
            st.stop()
    
    # 1. ì›ì¸ë³€ìˆ˜ ì„ íƒ
    st.write("#### 1. ì›ì¸ë³€ìˆ˜ ì„ íƒ")
    selected_features = st.multiselect(
        "ì›ì¸ë³€ìˆ˜ë¥¼ ì„ íƒí•˜ì„¸ìš” (ì—¬ëŸ¬ ê°œ ì„ íƒ ê°€ëŠ¥):",
        options=numeric_cols,
        help="ì˜ˆì¸¡ì— ì‚¬ìš©í•  ì›ì¸ë³€ìˆ˜ë“¤ì„ ì„ íƒí•˜ì„¸ìš”."
    )
    
    # 2. ê²°ê³¼ë³€ìˆ˜ ì„ íƒ
    st.write("#### 2. ê²°ê³¼ë³€ìˆ˜ ì„ íƒ")
    # ì›ì¸ë³€ìˆ˜ë¡œ ì„ íƒë˜ì§€ ì•Šì€ ë³€ìˆ˜ë“¤ ì¤‘ì—ì„œ ê²°ê³¼ë³€ìˆ˜ ì„ íƒ
    remaining_cols = [col for col in numeric_cols if col not in selected_features]
    target_col = st.selectbox(
        "ê²°ê³¼ë³€ìˆ˜ë¥¼ ì„ íƒí•˜ì„¸ìš”:",
        options=remaining_cols,
        help="ì˜ˆì¸¡í•˜ê³ ì í•˜ëŠ” ê²°ê³¼ë³€ìˆ˜ë¥¼ ì„ íƒí•˜ì„¸ìš”."
    )
    
    if selected_features and target_col:
        st.subheader(f"'{target_col}' ì˜ˆì¸¡ ëª¨ë¸ë§")
    
    # ë°ì´í„° ì „ì²˜ë¦¬
    numeric_data = data.select_dtypes(include=[np.number])
    
    # ìƒê´€ê´€ê³„ ë¶„ì„
    if target_col in numeric_data.columns:
        # NaN ê°’ ì²˜ë¦¬
        correlation_data = numeric_data.copy()
        correlation_data = correlation_data.fillna(correlation_data.mean())
        
        # ìƒê´€ê³„ìˆ˜ ê³„ì‚° - ì ˆëŒ€ê°’ì„ ì‚¬ìš©í•˜ì§€ ì•Šê³  ì›ë˜ ê°’ì„ ìœ ì§€
        correlations = correlation_data.corr()[target_col].sort_values(ascending=False)
        correlations = correlations.drop(target_col)  # íƒ€ê¹ƒ ë³€ìˆ˜ ìì‹ ê³¼ì˜ ìƒê´€ê´€ê³„ ì œì™¸
        
        # ìƒìœ„ ë³€ìˆ˜ ì„ íƒ ì‹œ ì ˆëŒ€ê°’ìœ¼ë¡œ ì •ë ¬í•˜ë˜, í‘œì‹œí•  ë•ŒëŠ” ì›ë˜ ê°’ ì‚¬ìš©
        top_indices = correlations.abs().sort_values(ascending=False).head(10).index
        correlation_with_target = correlations[top_indices]
        
        # ìƒê´€ê´€ê³„ ì‹œê°í™” (Plotlyë¡œ ë³€ê²½)
        fig_corr = go.Figure()
        
        # ìƒê´€ê³„ìˆ˜ì— ë”°ë¼ ìƒ‰ìƒ ì„¤ì •
        colors = ['#3498db' if val > 0 else '#e74c3c' for val in correlation_with_target.values]
        
        # ê°€ë¡œ ë§‰ëŒ€ ì°¨íŠ¸ ì¶”ê°€
        fig_corr.add_trace(
            go.Bar(
                y=correlation_with_target.index,
                x=correlation_with_target.values,  # ì›ë˜ ê°’ ì‚¬ìš© (ìŒìˆ˜/ì–‘ìˆ˜ ìœ ì§€)
                orientation='h',
                marker_color=colors,
                text=[f'{val:.2f}' for val in correlation_with_target.values],
                textposition='outside',
                hovertemplate='%{y}: %{x:.3f}<extra></extra>'
            )
        )
        
        # ë ˆì´ì•„ì›ƒ ì„¤ì •
        fig_corr.update_layout(
            title=f'{target_col}ì™€(ê³¼)ì˜ ìƒê´€ê´€ê³„ (ìƒìœ„ 10ê°œ)',
            xaxis_title='ìƒê´€ê³„ìˆ˜',
            yaxis_title='ë³€ìˆ˜',
            height=500,
            margin=dict(l=20, r=20, t=40, b=20),
            xaxis=dict(
                range=[-1, 1],  # xì¶• ë²”ìœ„ë¥¼ -1ì—ì„œ 1ë¡œ ê³ ì •
                zeroline=True,  # 0 ê¸°ì¤€ì„  ì¶”ê°€
                zerolinecolor='black',
                zerolinewidth=1
            )
        )
        
        # ì¤‘ì•™ì— í‘œì‹œ
        display_plotly_centered(fig_corr)
        
        # íƒ­ ìƒì„±
        tab1, tab2 = st.tabs(["ëª¨ë¸ í›ˆë ¨", "ì‹œë®¬ë ˆì´ì…˜"])
        
        with tab1:
            st.write("### ëª¨ë¸ í›ˆë ¨")
            
            # íšŒê·€ë¶„ì„ê³¼ ë¨¸ì‹ ëŸ¬ë‹ì˜ ì°¨ì´ì  ì„¤ëª…
            with st.expander("ğŸ’¡ íšŒê·€ë¶„ì„ê³¼ ë¨¸ì‹ ëŸ¬ë‹ì˜ ì°¨ì´ì  ì´í•´í•˜ê¸°", expanded=False):
                st.markdown("""
                ### íšŒê·€ë¶„ì„ê³¼ ë¨¸ì‹ ëŸ¬ë‹ì˜ ì°¨ì´ì 
                
                #### 1. ê¸°ë³¸ ê°œë…
                - **íšŒê·€ë¶„ì„**: ë³€ìˆ˜ ê°„ì˜ ê´€ê³„ë¥¼ ìˆ˜í•™ì  ë°©ì •ì‹ìœ¼ë¡œ í‘œí˜„í•˜ëŠ” í†µê³„ì  ë°©ë²•
                - **ë¨¸ì‹ ëŸ¬ë‹**: ë°ì´í„°ë¡œë¶€í„° íŒ¨í„´ì„ í•™ìŠµí•˜ì—¬ ì˜ˆì¸¡í•˜ëŠ” ë°©ë²•
                
                #### 2. ì£¼ìš” ì°¨ì´ì 
                
                **ğŸ“Š ì˜ˆì¸¡ ë°©ì‹**
                - **íšŒê·€ë¶„ì„**: 
                  - ì„ í˜• ê´€ê³„ë§Œ ê³ ë ¤ (y = ax + b í˜•íƒœ)
                  - ë³€ìˆ˜ ê°„ ê´€ê³„ê°€ ëª…í™•í•˜ê³  í•´ì„ ê°€ëŠ¥
                  - ì´ìƒì¹˜ì— ë¯¼ê°
                
                - **ë¨¸ì‹ ëŸ¬ë‹**: 
                  - ë¹„ì„ í˜• ê´€ê³„ë„ í•™ìŠµ ê°€ëŠ¥
                  - ë³µì¡í•œ íŒ¨í„´ ë°œê²¬ ê°€ëŠ¥
                  - ì´ìƒì¹˜ì— ë” ê°•ê±´í•¨
                
                **ğŸ” í•´ì„ì„±**
                - **íšŒê·€ë¶„ì„**: 
                  - ê²°ê³¼ê°€ ë§¤ìš° ëª…í™•í•˜ê³  í•´ì„í•˜ê¸° ì‰¬ì›€
                  - ê° ë³€ìˆ˜ì˜ ì˜í–¥ë ¥ì„ ì •í™•íˆ íŒŒì•… ê°€ëŠ¥
                  - í†µê³„ì  ìœ ì˜ì„± ê²€ì • ê°€ëŠ¥
                
                - **ë¨¸ì‹ ëŸ¬ë‹**: 
                  - ê²°ê³¼ í•´ì„ì´ ìƒëŒ€ì ìœ¼ë¡œ ì–´ë ¤ì›€
                  - 'ë¸”ë™ë°•ìŠ¤'ì²˜ëŸ¼ ì‘ë™í•  ìˆ˜ ìˆìŒ
                  - ë³€ìˆ˜ ì¤‘ìš”ë„ëŠ” íŒŒì•… ê°€ëŠ¥í•˜ë‚˜ ì •í™•í•œ ì˜í–¥ë ¥ì€ ì•Œê¸° ì–´ë ¤ì›€
                
                **ğŸ¯ ì í•©í•œ ìƒí™©**
                - **íšŒê·€ë¶„ì„ì´ ì¢‹ì€ ê²½ìš°**: 
                  - ë³€ìˆ˜ ê°„ ê´€ê³„ê°€ ì„ í˜•ì ì¼ ë•Œ
                  - ê²°ê³¼ì˜ í•´ì„ì´ ì¤‘ìš”í•  ë•Œ
                  - ë°ì´í„°ê°€ ì ì„ ë•Œ
                  - í†µê³„ì  ê²€ì •ì´ í•„ìš”í•  ë•Œ
                
                - **ë¨¸ì‹ ëŸ¬ë‹ì´ ì¢‹ì€ ê²½ìš°**: 
                  - ë³µì¡í•œ ë¹„ì„ í˜• ê´€ê³„ê°€ ìˆì„ ë•Œ
                  - ì˜ˆì¸¡ ì •í™•ë„ê°€ ê°€ì¥ ì¤‘ìš”í•  ë•Œ
                  - ë°ì´í„°ê°€ ë§ì„ ë•Œ
                  - ì‹¤ì‹œê°„ ì˜ˆì¸¡ì´ í•„ìš”í•  ë•Œ
                
                #### 3. ì‹¤ì œ ì ìš© ì‹œ ê³ ë ¤ì‚¬í•­
                - **ë°ì´í„°ì˜ íŠ¹ì„±**: 
                  - ë°ì´í„°ê°€ ì ìœ¼ë©´ íšŒê·€ë¶„ì„ì´ ë” ì•ˆì •ì 
                  - ë°ì´í„°ê°€ ë§ìœ¼ë©´ ë¨¸ì‹ ëŸ¬ë‹ì´ ë” ì •í™•í•  ìˆ˜ ìˆìŒ
                
                - **ëª©ì ì— ë”°ë¥¸ ì„ íƒ**: 
                  - í•´ì„ì´ ì¤‘ìš”í•˜ë©´ â†’ íšŒê·€ë¶„ì„
                  - ì˜ˆì¸¡ ì •í™•ë„ê°€ ì¤‘ìš”í•˜ë©´ â†’ ë¨¸ì‹ ëŸ¬ë‹
                
                - **ì‹¤ì œ ì‚¬ë¡€**: 
                  - í’ˆì§ˆ ê´€ë¦¬ì—ì„œëŠ” ë‘ ë°©ë²•ì„ ëª¨ë‘ ì‚¬ìš©
                  - ì´ˆê¸° ë¶„ì„ì—ëŠ” íšŒê·€ë¶„ì„ìœ¼ë¡œ ê´€ê³„ íŒŒì•…
                  - ì‹¤ì œ ì˜ˆì¸¡ì—ëŠ” ë¨¸ì‹ ëŸ¬ë‹ í™œìš©
                """)
            
            # ëª¨ë¸ ì„ íƒ
            st.write("### ëª¨ë¸ ì„ íƒ")
            
            # ëª¨ë¸ ì„¤ëª… ì¶”ê°€
            with st.expander("ğŸ’¡ ê° ëª¨ë¸ì˜ íŠ¹ì§•", expanded=False):
                st.markdown("""
                ### ëª¨ë¸ ì¢…ë¥˜ì™€ íŠ¹ì§•
                
                #### 1. RandomForest (ëœë¤ í¬ë ˆìŠ¤íŠ¸)
                - ì—¬ëŸ¬ ê°œì˜ ì˜ì‚¬ê²°ì • ë‚˜ë¬´ë¥¼ ê²°í•©í•œ ì•™ìƒë¸” ëª¨ë¸
                - ì•ˆì •ì ì´ê³  ê³¼ì í•©ì— ê°•í•¨
                - ë³µì¡í•œ ê´€ê³„ë„ ì˜ í•™ìŠµ
                
                #### 2. XGBoost (ì—‘ìŠ¤ì§€ë¶€ìŠ¤íŠ¸)
                - ê°€ì¥ ì„±ëŠ¥ì´ ì¢‹ì€ ë¶€ìŠ¤íŒ… ì•Œê³ ë¦¬ì¦˜ ì¤‘ í•˜ë‚˜
                - ë†’ì€ ì˜ˆì¸¡ ì •í™•ë„
                - ê³„ì‚° ì†ë„ê°€ ë¹ ë¦„
                
                #### 3. ì„ í˜• íšŒê·€
                - ê°€ì¥ ê¸°ë³¸ì ì¸ í†µê³„ ëª¨ë¸
                - ê²°ê³¼ í•´ì„ì´ ì‰½ê³  ì§ê´€ì 
                - ë‹¨ìˆœí•œ ì„ í˜• ê´€ê³„ì— ì í•©
                """)
            
            model_type = st.radio(
                "ëª¨ë¸ ì„ íƒ:",
                ["RandomForest", "XGBoost", "ì„ í˜• íšŒê·€"],
                horizontal=True
            )
            
            # í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì˜µì…˜ ì¶”ê°€
            tune_hyperparams = st.checkbox("í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì ìš©", value=False,
                                          help="ëª¨ë¸ì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ìë™ìœ¼ë¡œ ìµœì í™”í•©ë‹ˆë‹¤.")
            
            # ë°ì´í„° ì „ì²˜ë¦¬ ì˜µì…˜
            st.write("### ë°ì´í„° ì „ì²˜ë¦¬ ì˜µì…˜")
            
            # ë°ì´í„° ì¦ê°• ì˜µì…˜ ì¶”ê°€
            data_augmentation_options = st.expander("ë°ì´í„° ì¦ê°• ì˜µì…˜", expanded=False)
            with data_augmentation_options:
                apply_augmentation = st.checkbox("ë°ì´í„° ì¦ê°• ì ìš©", value=False,
                                               help="ë°ì´í„° ì¦ê°•ì„ í†µí•´ í•™ìŠµ ë°ì´í„°ë¥¼ ëŠ˜ë¦½ë‹ˆë‹¤.")
                
                if apply_augmentation:
                    augmentation_method = st.radio(
                        "ì¦ê°• ë°©ë²•:",
                        ["SMOTE", "ê°€ìš°ì‹œì•ˆ ë…¸ì´ì¦ˆ", "ì„ í˜• ë³´ê°„"],
                        horizontal=True,
                        help="SMOTE: ì†Œìˆ˜ í´ë˜ìŠ¤ì˜ ìƒ˜í”Œì„ ë³´ê°„í•˜ì—¬ ì¦ê°•\nê°€ìš°ì‹œì•ˆ ë…¸ì´ì¦ˆ: ê¸°ì¡´ ë°ì´í„°ì— ë…¸ì´ì¦ˆë¥¼ ì¶”ê°€\nì„ í˜• ë³´ê°„: ê¸°ì¡´ ë°ì´í„° í¬ì¸íŠ¸ ì‚¬ì´ë¥¼ ë³´ê°„"
                    )
                    
                    if augmentation_method == "SMOTE":
                        # SMOTEëŠ” ë¶„ë¥˜ ë¬¸ì œì— ì£¼ë¡œ ì‚¬ìš©ë˜ë¯€ë¡œ, íšŒê·€ ë¬¸ì œì— ë§ê²Œ ìˆ˜ì •
                        st.info("SMOTEëŠ” ë¶„ë¥˜ ë¬¸ì œì— ì£¼ë¡œ ì‚¬ìš©ë˜ì§€ë§Œ, íšŒê·€ ë¬¸ì œì—ë„ ì ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                        smote_samples = st.slider("ìƒì„±í•  ìƒ˜í”Œ ìˆ˜", 
                                                min_value=10, max_value=100, value=50, step=10,
                                                help="ìƒì„±í•  ìƒ˜í”Œ ìˆ˜ë¥¼ ì„ íƒí•˜ì„¸ìš”. ë„ˆë¬´ ë§ì€ ìƒ˜í”Œì€ ê³¼ì í•©ì„ ìœ ë°œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                    
                    elif augmentation_method == "ê°€ìš°ì‹œì•ˆ ë…¸ì´ì¦ˆ":
                        noise_level = st.slider("ë…¸ì´ì¦ˆ ìˆ˜ì¤€", 
                                              min_value=0.01, max_value=0.1, value=0.05, step=0.01,
                                              help="ì¶”ê°€í•  ë…¸ì´ì¦ˆì˜ í‘œì¤€í¸ì°¨ë¥¼ ì„ íƒí•˜ì„¸ìš”.")
                        noise_samples = st.slider("ìƒì„±í•  ìƒ˜í”Œ ìˆ˜", 
                                                min_value=10, max_value=100, value=50, step=10,
                                                help="ìƒì„±í•  ìƒ˜í”Œ ìˆ˜ë¥¼ ì„ íƒí•˜ì„¸ìš”.")
                    
                    else:  # ì„ í˜• ë³´ê°„
                        interpolation_samples = st.slider("ë³´ê°„ ìƒ˜í”Œ ìˆ˜", 
                                                        min_value=10, max_value=100, value=50, step=10,
                                                        help="ê¸°ì¡´ ë°ì´í„° í¬ì¸íŠ¸ ì‚¬ì´ì— ìƒì„±í•  ìƒ˜í”Œ ìˆ˜ë¥¼ ì„ íƒí•˜ì„¸ìš”.")
            
            # ì´ìƒì¹˜ ì²˜ë¦¬ ì˜µì…˜
            outlier_options = st.expander("ì´ìƒì¹˜ ì²˜ë¦¬ ì˜µì…˜", expanded=True)
            with outlier_options:
                remove_outliers = st.checkbox("ì´ìƒì¹˜ ì œê±°", value=True, 
                                            help="í•™ìŠµ ë°ì´í„°ì—ì„œ ì´ìƒì¹˜ë¥¼ ì œê±°í•˜ì—¬ ëª¨ë¸ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.")
                
                outlier_method = st.radio(
                    "ì´ìƒì¹˜ íƒì§€ ë°©ë²•:",
                    ["Z-ì ìˆ˜", "IQR ë°©ë²•"],
                    horizontal=True,
                    help="Z-ì ìˆ˜: í‰ê· ì—ì„œ n í‘œì¤€í¸ì°¨ ì´ìƒ ë–¨ì–´ì§„ ê°’ì„ ì´ìƒì¹˜ë¡œ ê°„ì£¼\nIQR: ì‚¬ë¶„ìœ„ìˆ˜ ë²”ìœ„ë¥¼ ë²—ì–´ë‚œ ê°’ì„ ì´ìƒì¹˜ë¡œ ê°„ì£¼"
                )
                
                if outlier_method == "Z-ì ìˆ˜":
                    z_threshold = st.slider("Z-ì ìˆ˜ ì„ê³„ê°’", 
                                          min_value=2.0, max_value=5.0, value=3.0, step=0.1,
                                          help="ì´ ê°’ë³´ë‹¤ í° Z-ì ìˆ˜ë¥¼ ê°€ì§„ ë°ì´í„°ë¥¼ ì´ìƒì¹˜ë¡œ ê°„ì£¼í•©ë‹ˆë‹¤.")
                else:  # IQR ë°©ë²•
                    iqr_multiplier = st.slider("IQR ê³±ìˆ˜", 
                                             min_value=1.0, max_value=3.0, value=1.5, step=0.1,
                                             help="IQR Ã— ì´ ê°’ì„ ì´ˆê³¼í•˜ëŠ” ë°ì´í„°ë¥¼ ì´ìƒì¹˜ë¡œ ê°„ì£¼í•©ë‹ˆë‹¤.")
            
            # ë°ì´í„° ìŠ¤ì¼€ì¼ë§ ì˜µì…˜
            scaling_options = st.expander("ë°ì´í„° ìŠ¤ì¼€ì¼ë§ ì˜µì…˜", expanded=True)
            with scaling_options:
                apply_scaling = st.checkbox("ë°ì´í„° ìŠ¤ì¼€ì¼ë§ ì ìš©", value=True,
                                          help="ë³€ìˆ˜ë¥¼ ë™ì¼í•œ ìŠ¤ì¼€ì¼ë¡œ ì¡°ì •í•˜ì—¬ ëª¨ë¸ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.")
                
                if apply_scaling:
                    scaler_method = st.radio(
                        "ìŠ¤ì¼€ì¼ë§ ë°©ë²•:",
                        ["í‘œì¤€í™”(StandardScaler)", "ë¡œë²„ìŠ¤íŠ¸ ìŠ¤ì¼€ì¼ë§(RobustScaler)", "ì •ê·œí™”(MinMaxScaler)"],
                        horizontal=True,
                        help="í‘œì¤€í™”: í‰ê·  0, í‘œì¤€í¸ì°¨ 1ë¡œ ë³€í™˜\në¡œë²„ìŠ¤íŠ¸: ì¤‘ì•™ê°’ê³¼ IQRì„ ì‚¬ìš©í•˜ì—¬ ì´ìƒì¹˜ì— ê°•ê±´í•œ ìŠ¤ì¼€ì¼ë§\nì •ê·œí™”: ìµœì†Œ-ìµœëŒ€ ìŠ¤ì¼€ì¼ë§ìœ¼ë¡œ 0~1 ë²”ìœ„ë¡œ ë³€í™˜"
                    )
            
            # í›ˆë ¨ ë²„íŠ¼
            if st.button("ëª¨ë¸ í›ˆë ¨"):
                with st.spinner("ëª¨ë¸ í›ˆë ¨ ì¤‘..."):
                    # ì›ë³¸ ë°ì´í„° ë³´ì¡´
                    X_orig = correlation_data[top_indices].copy()
                    y_orig = correlation_data[target_col].copy()
                    
                    # ì´ìƒì¹˜ í™•ì¸ ë° ì‹œê°í™”
                    if remove_outliers:
                        if outlier_method == "Z-ì ìˆ˜":
                            # ì´ìƒì¹˜ ì œê±° ì „ ë°ì´í„° ê±´ìˆ˜
                            before_count = len(X_orig)
                            
                            # Z-ì ìˆ˜ ê³„ì‚° ë° ì´ìƒì¹˜ ì‹ë³„
                            z_scores = np.abs((X_orig - X_orig.mean()) / X_orig.std())
                            outlier_mask = (z_scores > z_threshold).any(axis=1)
                            
                            # íƒ€ê²Ÿ ë³€ìˆ˜ì˜ Z-ì ìˆ˜ë„ ê³„ì‚°
                            y_z_score = np.abs((y_orig - y_orig.mean()) / y_orig.std())
                            y_outlier_mask = (y_z_score > z_threshold)
                            
                            # ì´ìƒì¹˜ê°€ ìˆëŠ” í–‰ì„ ì‹ë³„
                            combined_mask = outlier_mask | y_outlier_mask
                            
                            # ì´ìƒì¹˜ ì œê±°ëœ ë°ì´í„°
                            X_cleaned = X_orig[~combined_mask]
                            y_cleaned = y_orig[~combined_mask]
                            
                            # ì œê±°ëœ ë°ì´í„° ìˆ˜ ê³„ì‚°
                            removed_count = before_count - len(X_cleaned)
                            removal_percentage = (removed_count / before_count) * 100
                            
                            st.info(f"Z-ì ìˆ˜ {z_threshold} ì´ìƒì¸ ì´ìƒì¹˜ {removed_count}ê°œ({removal_percentage:.1f}%)ë¥¼ ì œê±°í–ˆìŠµë‹ˆë‹¤. (ì›ë³¸: {before_count}ê°œ â†’ ì •ì œ: {len(X_cleaned)}ê°œ)")
                            
                        else:  # IQR ë°©ë²•
                            # ì´ìƒì¹˜ ì œê±° ì „ ë°ì´í„° ê±´ìˆ˜
                            before_count = len(X_orig)
                            
                            # ê° íŠ¹ì„±ì— ëŒ€í•´ IQR ê¸°ë°˜ ì´ìƒì¹˜ íƒì§€
                            outlier_rows = []
                            for col in X_orig.columns:
                                Q1 = X_orig[col].quantile(0.25)
                                Q3 = X_orig[col].quantile(0.75)
                                IQR = Q3 - Q1
                                lower_bound = Q1 - iqr_multiplier * IQR
                                upper_bound = Q3 + iqr_multiplier * IQR
                                
                                # ì´ìƒì¹˜ê°€ ìˆëŠ” í–‰ ì¸ë±ìŠ¤
                                feature_outliers = X_orig[(X_orig[col] < lower_bound) | (X_orig[col] > upper_bound)].index
                                outlier_rows.extend(feature_outliers)
                            
                            # íƒ€ê²Ÿ ë³€ìˆ˜ì˜ ì´ìƒì¹˜ë„ í™•ì¸
                            Q1 = y_orig.quantile(0.25)
                            Q3 = y_orig.quantile(0.75)
                            IQR = Q3 - Q1
                            lower_bound = Q1 - iqr_multiplier * IQR
                            upper_bound = Q3 + iqr_multiplier * IQR
                            
                            target_outliers = y_orig[(y_orig < lower_bound) | (y_orig > upper_bound)].index
                            outlier_rows.extend(target_outliers)
                            
                            # ì¤‘ë³µ ì œê±°í•˜ì—¬ ì´ìƒì¹˜ê°€ ìˆëŠ” ëª¨ë“  í–‰ ì¸ë±ìŠ¤
                            outlier_indices = list(set(outlier_rows))
                            
                            # ì´ìƒì¹˜ ì œê±°
                            X_cleaned = X_orig.drop(outlier_indices)
                            y_cleaned = y_orig.drop(outlier_indices)
                            
                            # ì œê±°ëœ ë°ì´í„° ìˆ˜ ê³„ì‚°
                            removed_count = before_count - len(X_cleaned)
                            removal_percentage = (removed_count / before_count) * 100
                            
                            st.info(f"IQR Ã— {iqr_multiplier} ë²”ìœ„ë¥¼ ë²—ì–´ë‚œ ì´ìƒì¹˜ {removed_count}ê°œ({removal_percentage:.1f}%)ë¥¼ ì œê±°í–ˆìŠµë‹ˆë‹¤. (ì›ë³¸: {before_count}ê°œ â†’ ì •ì œ: {len(X_cleaned)}ê°œ)")
                    else:
                        # ì´ìƒì¹˜ ì œê±° ì—†ì´ ì›ë³¸ ë°ì´í„° ì‚¬ìš©
                        X_cleaned = X_orig.copy()
                        y_cleaned = y_orig.copy()
                    
                    # ë°ì´í„° ì¦ê°• ì ìš©
                    if apply_augmentation:
                        # ë°ì´í„° ì¦ê°• ì „ ë°ì´í„° ê±´ìˆ˜
                        before_aug_count = len(X_cleaned)
                        
                        # ë°ì´í„° ì¦ê°• ë°©ë²•ì— ë”°ë¼ ì ìš©
                        if augmentation_method == "SMOTE":
                            # SMOTEëŠ” ë¶„ë¥˜ ë¬¸ì œì— ì£¼ë¡œ ì‚¬ìš©ë˜ë¯€ë¡œ, íšŒê·€ ë¬¸ì œì— ë§ê²Œ ìˆ˜ì •
                            from sklearn.neighbors import NearestNeighbors
                            
                            # ë°ì´í„° ì¦ê°•ì„ ìœ„í•œ í•¨ìˆ˜
                            def smote_for_regression(X, y, n_samples):
                                # ë°ì´í„° ì¦ê°•ì„ ìœ„í•œ ê²°ê³¼ ì €ì¥
                                X_aug = X.copy()
                                y_aug = y.copy()
                                
                                # íƒ€ê²Ÿ ë³€ìˆ˜ë¥¼ êµ¬ê°„ìœ¼ë¡œ ë‚˜ëˆ„ì–´ ê° êµ¬ê°„ë³„ë¡œ ìƒ˜í”Œë§
                                y_bins = pd.qcut(y, q=5, labels=False)
                                
                                # ê° êµ¬ê°„ë³„ë¡œ SMOTE ì ìš©
                                for i in range(5):
                                    # í˜„ì¬ êµ¬ê°„ì˜ ì¸ë±ìŠ¤
                                    current_indices = np.where(y_bins == i)[0]
                                    
                                    if len(current_indices) < 2:
                                        continue
                                    
                                    # í˜„ì¬ êµ¬ê°„ì˜ ë°ì´í„°
                                    X_current = X.iloc[current_indices]
                                    y_current = y.iloc[current_indices]
                                    
                                    # k-ìµœê·¼ì ‘ ì´ì›ƒ ì°¾ê¸°
                                    nbrs = NearestNeighbors(n_neighbors=2).fit(X_current)
                                    distances, indices = nbrs.kneighbors(X_current)
                                    
                                    # ê° ìƒ˜í”Œì— ëŒ€í•´ ë³´ê°„
                                    for j in range(min(n_samples // 5, len(current_indices))):
                                        # ëœë¤í•˜ê²Œ ë‘ ì´ì›ƒ ì„ íƒ
                                        idx = np.random.randint(0, len(current_indices))
                                        neighbor_idx = indices[idx, 1]
                                        
                                        # ë³´ê°„ ê³„ìˆ˜
                                        alpha = np.random.random()
                                        
                                        # ë³´ê°„ëœ ìƒ˜í”Œ ìƒì„±
                                        X_interp = X_current.iloc[idx] * (1 - alpha) + X_current.iloc[neighbor_idx] * alpha
                                        y_interp = y_current.iloc[idx] * (1 - alpha) + y_current.iloc[neighbor_idx] * alpha
                                        
                                        # ì¦ê°•ëœ ë°ì´í„° ì¶”ê°€
                                        X_aug = pd.concat([X_aug, pd.DataFrame([X_interp], columns=X.columns)], ignore_index=True)
                                        y_aug = pd.concat([y_aug, pd.Series([y_interp], name=y.name)], ignore_index=True)
                                
                                return X_aug, y_aug
                            
                            # SMOTE ì ìš©
                            X_aug, y_aug = smote_for_regression(X_cleaned, y_cleaned, smote_samples)
                            
                            # ì¦ê°•ëœ ë°ì´í„° ìˆ˜ ê³„ì‚°
                            aug_count = len(X_aug) - before_aug_count
                            aug_percentage = (aug_count / before_aug_count) * 100
                            
                            st.success(f"SMOTEë¥¼ í†µí•´ {aug_count}ê°œ({aug_percentage:.1f}%)ì˜ ìƒ˜í”Œì„ ì¦ê°•í–ˆìŠµë‹ˆë‹¤. (ì›ë³¸: {before_aug_count}ê°œ â†’ ì¦ê°•: {len(X_aug)}ê°œ)")
                            
                            # ì¦ê°•ëœ ë°ì´í„° ì‚¬ìš©
                            X_cleaned = X_aug
                            y_cleaned = y_aug
                            
                        elif augmentation_method == "ê°€ìš°ì‹œì•ˆ ë…¸ì´ì¦ˆ":
                            # ê°€ìš°ì‹œì•ˆ ë…¸ì´ì¦ˆ ì¶”ê°€
                            X_aug = X_cleaned.copy()
                            y_aug = y_cleaned.copy()
                            
                            for _ in range(noise_samples):
                                # ëœë¤í•˜ê²Œ ì›ë³¸ ë°ì´í„° ì„ íƒ
                                idx = np.random.randint(0, len(X_cleaned))
                                
                                # ê°€ìš°ì‹œì•ˆ ë…¸ì´ì¦ˆ ìƒì„±
                                X_noise = X_cleaned.iloc[idx] + np.random.normal(0, noise_level, size=len(X_cleaned.columns))
                                y_noise = y_cleaned.iloc[idx] + np.random.normal(0, noise_level)
                                
                                # ì¦ê°•ëœ ë°ì´í„° ì¶”ê°€
                                X_aug = pd.concat([X_aug, pd.DataFrame([X_noise], columns=X_cleaned.columns)], ignore_index=True)
                                y_aug = pd.concat([y_aug, pd.Series([y_noise], name=y_cleaned.name)], ignore_index=True)
                            
                            # ì¦ê°•ëœ ë°ì´í„° ìˆ˜ ê³„ì‚°
                            aug_count = len(X_aug) - before_aug_count
                            aug_percentage = (aug_count / before_aug_count) * 100
                            
                            st.success(f"ê°€ìš°ì‹œì•ˆ ë…¸ì´ì¦ˆë¥¼ í†µí•´ {aug_count}ê°œ({aug_percentage:.1f}%)ì˜ ìƒ˜í”Œì„ ì¦ê°•í–ˆìŠµë‹ˆë‹¤. (ì›ë³¸: {before_aug_count}ê°œ â†’ ì¦ê°•: {len(X_aug)}ê°œ)")
                            
                            # ì¦ê°•ëœ ë°ì´í„° ì‚¬ìš©
                            X_cleaned = X_aug
                            y_cleaned = y_aug
                            
                        else:  # ì„ í˜• ë³´ê°„
                            # ì„ í˜• ë³´ê°„
                            X_aug = X_cleaned.copy()
                            y_aug = y_cleaned.copy()
                            
                            # ë°ì´í„° í¬ì¸íŠ¸ ìŒ ìƒì„±
                            pairs = []
                            for i in range(len(X_cleaned)):
                                for j in range(i+1, len(X_cleaned)):
                                    pairs.append((i, j))
                            
                            # ëœë¤í•˜ê²Œ ìŒ ì„ íƒ
                            if len(pairs) > interpolation_samples:
                                selected_pairs = np.random.choice(len(pairs), interpolation_samples, replace=False)
                            else:
                                selected_pairs = np.arange(len(pairs))
                            
                            # ì„ íƒëœ ìŒì— ëŒ€í•´ ë³´ê°„
                            for pair_idx in selected_pairs:
                                i, j = pairs[pair_idx]
                                
                                # ë³´ê°„ ê³„ìˆ˜
                                alpha = np.random.random()
                                
                                # ë³´ê°„ëœ ìƒ˜í”Œ ìƒì„±
                                X_interp = X_cleaned.iloc[i] * (1 - alpha) + X_cleaned.iloc[j] * alpha
                                y_interp = y_cleaned.iloc[i] * (1 - alpha) + y_cleaned.iloc[j] * alpha
                                
                                # ì¦ê°•ëœ ë°ì´í„° ì¶”ê°€
                                X_aug = pd.concat([X_aug, pd.DataFrame([X_interp], columns=X_cleaned.columns)], ignore_index=True)
                                y_aug = pd.concat([y_aug, pd.Series([y_interp], name=y_cleaned.name)], ignore_index=True)
                            
                            # ì¦ê°•ëœ ë°ì´í„° ìˆ˜ ê³„ì‚°
                            aug_count = len(X_aug) - before_aug_count
                            aug_percentage = (aug_count / before_aug_count) * 100
                            
                            st.success(f"ì„ í˜• ë³´ê°„ì„ í†µí•´ {aug_count}ê°œ({aug_percentage:.1f}%)ì˜ ìƒ˜í”Œì„ ì¦ê°•í–ˆìŠµë‹ˆë‹¤. (ì›ë³¸: {before_aug_count}ê°œ â†’ ì¦ê°•: {len(X_aug)}ê°œ)")
                            
                            # ì¦ê°•ëœ ë°ì´í„° ì‚¬ìš©
                            X_cleaned = X_aug
                            y_cleaned = y_aug
                    
                    # ë°ì´í„° ë¶€ì¡± ì‹œ ê²½ê³ 
                    if len(X_cleaned) < 20:
                        st.warning("ë°ì´í„°ê°€ ë„ˆë¬´ ì ìŠµë‹ˆë‹¤(20ê°œ ë¯¸ë§Œ). ëª¨ë¸ ì„±ëŠ¥ì´ ì¢‹ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                        if remove_outliers:
                            st.warning("ì´ìƒì¹˜ ì œê±° ê¸°ì¤€ì„ ì™„í™”í•˜ê±°ë‚˜ ë¹„í™œì„±í™”í•˜ëŠ” ê²ƒì„ ê³ ë ¤í•˜ì„¸ìš”.")
                    
                    # ìŠ¤ì¼€ì¼ë§ ì ìš©
                    if apply_scaling:
                        if scaler_method == "í‘œì¤€í™”(StandardScaler)":
                            scaler = StandardScaler()
                            st.session_state.scaler = scaler
                            st.session_state.scaling_method = "standard"
                        elif scaler_method == "ë¡œë²„ìŠ¤íŠ¸ ìŠ¤ì¼€ì¼ë§(RobustScaler)":
                            scaler = RobustScaler()
                            st.session_state.scaler = scaler
                            st.session_state.scaling_method = "robust"
                        else:  # ì •ê·œí™”(MinMaxScaler)
                            scaler = MinMaxScaler()
                            st.session_state.scaler = scaler
                            st.session_state.scaling_method = "minmax"
                        
                        # X ë°ì´í„° ìŠ¤ì¼€ì¼ë§
                        X_scaled = pd.DataFrame(
                            scaler.fit_transform(X_cleaned),
                            columns=X_cleaned.columns,
                            index=X_cleaned.index
                        )
                        
                        st.info(f"{scaler_method}ë¥¼ ì ìš©í–ˆìŠµë‹ˆë‹¤.")
                    else:
                        X_scaled = X_cleaned
                        st.session_state.scaling_method = None
                    
                    # í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë¶„í• 
                    X_train, X_test, y_train, y_test = train_test_split(
                        X_scaled, y_cleaned, test_size=0.2, random_state=42
                    )
                    
                    # ëª¨ë¸ í›ˆë ¨
                    if model_type == "RandomForest":
                        if tune_hyperparams:
                            # í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹
                            from sklearn.model_selection import RandomizedSearchCV
                            
                            # íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ ì •ì˜
                            param_dist = {
                                'n_estimators': [50, 100, 200, 300, 500],
                                'max_depth': [None, 10, 20, 30, 40, 50],
                                'min_samples_split': [2, 5, 10],
                                'min_samples_leaf': [1, 2, 4]
                            }
                            
                            # ê¸°ë³¸ ëª¨ë¸
                            base_model = RandomForestRegressor(random_state=42)
                            
                            # RandomizedSearchCV ì„¤ì •
                            random_search = RandomizedSearchCV(
                                estimator=base_model,
                                param_distributions=param_dist,
                                n_iter=20,  # ì‹œë„í•  íŒŒë¼ë¯¸í„° ì¡°í•© ìˆ˜
                                scoring='neg_mean_squared_error',
                                cv=5,  # 5-fold êµì°¨ ê²€ì¦
                                verbose=0,
                                random_state=42,
                                n_jobs=-1  # ëª¨ë“  CPU ì½”ì–´ ì‚¬ìš©
                            )
                            
                            # í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì‹¤í–‰
                            with st.spinner("í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì¤‘..."):
                                random_search.fit(X_train, y_train)
                            
                            # ìµœì  íŒŒë¼ë¯¸í„° ì¶œë ¥
                            st.success(f"ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„°: {random_search.best_params_}")
                            
                            # ìµœì  ëª¨ë¸ ì„ íƒ
                            model = random_search.best_estimator_
                        else:
                            model = RandomForestRegressor(n_estimators=100, random_state=42)
                            model.fit(X_train, y_train)
                            
                    elif model_type == "XGBoost":
                        if tune_hyperparams:
                            # í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹
                            from sklearn.model_selection import RandomizedSearchCV
                            
                            # íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ ì •ì˜
                            param_dist = {
                                'n_estimators': [50, 100, 200, 300, 500],
                                'max_depth': [3, 5, 7, 9, 11],
                                'learning_rate': [0.01, 0.05, 0.1, 0.2],
                                'subsample': [0.6, 0.8, 1.0],
                                'colsample_bytree': [0.6, 0.8, 1.0]
                            }
                            
                            # ê¸°ë³¸ ëª¨ë¸
                            base_model = xgb.XGBRegressor(random_state=42)
                            
                            # RandomizedSearchCV ì„¤ì •
                            random_search = RandomizedSearchCV(
                                estimator=base_model,
                                param_distributions=param_dist,
                                n_iter=20,  # ì‹œë„í•  íŒŒë¼ë¯¸í„° ì¡°í•© ìˆ˜
                                scoring='neg_mean_squared_error',
                                cv=5,  # 5-fold êµì°¨ ê²€ì¦
                                verbose=0,
                                random_state=42,
                                n_jobs=-1  # ëª¨ë“  CPU ì½”ì–´ ì‚¬ìš©
                            )
                            
                            # í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì‹¤í–‰
                            with st.spinner("í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì¤‘..."):
                                random_search.fit(X_train, y_train)
                            
                            # ìµœì  íŒŒë¼ë¯¸í„° ì¶œë ¥
                            st.success(f"ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„°: {random_search.best_params_}")
                            
                            # ìµœì  ëª¨ë¸ ì„ íƒ
                            model = random_search.best_estimator_
                        else:
                            model = xgb.XGBRegressor(n_estimators=100, random_state=42)
                            model.fit(X_train, y_train)
                            
                    else:  # ì„ í˜• íšŒê·€
                        from sklearn.linear_model import LinearRegression
                        model = LinearRegression()
                        model.fit(X_train, y_train)
                    
                    # ëª¨ë¸ í‰ê°€
                    y_pred = model.predict(X_test)
                    mse = mean_squared_error(y_test, y_pred)
                    rmse = np.sqrt(mse)
                    r2 = r2_score(y_test, y_pred)
                    
                    # ê²°ê³¼ ì¶œë ¥
                    st.write(f"**í‰ê·  ì œê³± ì˜¤ì°¨(MSE):** {mse:.4f}")
                    st.write(f"**í‰ê·  ì œê³±ê·¼ ì˜¤ì°¨(RMSE):** {rmse:.4f}")
                    st.write(f"**RÂ² ì ìˆ˜:** {r2:.4f}")
                    
                    # íšŒê·€ ë¶„ì„ ê²°ê³¼ (ì„ í˜• íšŒê·€ ëª¨ë¸ì¸ ê²½ìš°)
                    if model_type == "ì„ í˜• íšŒê·€":
                        st.markdown("### íšŒê·€ ë¶„ì„ ê²°ê³¼")
                        
                        # íšŒê·€ ë¶„ì„ í•´ì„ ê°€ì´ë“œë¥¼ ë¨¼ì € í‘œì‹œ
                        with st.expander("ğŸ’¡ íšŒê·€ ë¶„ì„ ê²°ê³¼ ì‰½ê²Œ ì´í•´í•˜ê¸°", expanded=False):
                            st.markdown("""
                            ### íšŒê·€ ë¶„ì„ ê²°ê³¼ ì‰½ê²Œ ì´í•´í•˜ê¸°
                            
                            #### 1. íšŒê·€ ë¶„ì„ ê²°ê³¼ í‘œ í•´ì„
                            - **íšŒê·€ ê³„ìˆ˜**: ë³€ìˆ˜ê°€ 1 ì¦ê°€í•  ë•Œ ì˜ˆì¸¡ê°’ì´ ì–¼ë§ˆë‚˜ ë³€í•˜ëŠ”ì§€ ë‚˜íƒ€ë‚´ìš”
                              - **ì–‘ìˆ˜**: ì´ ë³€ìˆ˜ê°€ 1 ì¦ê°€í•˜ë©´ â†’ ì˜ˆì¸¡ê°’ë„ ì¦ê°€í•´ìš”
                              - **ìŒìˆ˜**: ì´ ë³€ìˆ˜ê°€ 1 ì¦ê°€í•˜ë©´ â†’ ì˜ˆì¸¡ê°’ì€ ê°ì†Œí•´ìš”
                              - **í¬ê¸°**: ìˆ«ìê°€ í´ìˆ˜ë¡ â†’ ì˜í–¥ë ¥ì´ ì»¤ìš”
                            
                            - **í‘œì¤€ ì˜¤ì°¨**: íšŒê·€ ê³„ìˆ˜ì˜ ë¶ˆí™•ì‹¤ì„±ì„ ë‚˜íƒ€ë‚´ìš”
                              - **ì‘ì„ìˆ˜ë¡**: ê³„ìˆ˜ê°€ ë” ì •í™•í•˜ë‹¤ëŠ” ì˜ë¯¸ì˜ˆìš”
                              - **í´ìˆ˜ë¡**: ê³„ìˆ˜ê°€ ë¶ˆí™•ì‹¤í•˜ë‹¤ëŠ” ì˜ë¯¸ì˜ˆìš”
                            
                            - **t í†µê³„ëŸ‰**: íšŒê·€ ê³„ìˆ˜ê°€ 0ê³¼ ë‹¤ë¥¸ì§€ ê²€ì •í•˜ëŠ” ê°’ì´ì—ìš”
                              - **ì ˆëŒ€ê°’ì´ í´ìˆ˜ë¡**: ë³€ìˆ˜ê°€ ë” ì¤‘ìš”í•˜ë‹¤ëŠ” ì˜ë¯¸ì˜ˆìš”
                              - **ì¼ë°˜ì ìœ¼ë¡œ 2 ì´ìƒ**: ë³€ìˆ˜ê°€ ì¤‘ìš”í•˜ë‹¤ê³  ë³¼ ìˆ˜ ìˆì–´ìš”
                            
                            - **p-value**: ë³€ìˆ˜ê°€ í†µê³„ì ìœ¼ë¡œ ì˜ë¯¸ ìˆëŠ”ì§€ ë‚˜íƒ€ë‚´ìš”
                              - **0.05ë³´ë‹¤ ì‘ìœ¼ë©´**: ì´ ë³€ìˆ˜ê°€ ì •ë§ ì¤‘ìš”í•œ ê±°ì˜ˆìš”! (í†µê³„ì ìœ¼ë¡œ ì˜ë¯¸ ìˆì–´ìš”)
                              - **0.05ë³´ë‹¤ í¬ë©´**: ì´ ë³€ìˆ˜ëŠ” í¬ê²Œ ì¤‘ìš”í•˜ì§€ ì•Šì•„ìš”
                            
                            #### 2. RÂ² ì ìˆ˜ëŠ”?
                            - **1ì— ê°€ê¹Œìš¸ìˆ˜ë¡**: ëª¨ë¸ì´ ì •ë§ ì˜ ì˜ˆì¸¡í•˜ëŠ” ê±°ì˜ˆìš”
                            - **0ì— ê°€ê¹Œìš¸ìˆ˜ë¡**: ëª¨ë¸ì´ ì˜ ì˜ˆì¸¡í•˜ì§€ ëª»í•˜ëŠ” ê±°ì˜ˆìš”
                            - **ì¼ë°˜ì ìœ¼ë¡œ 0.7 ì´ìƒ**: ì¢‹ì€ ëª¨ë¸ì´ë¼ê³  ë³¼ ìˆ˜ ìˆì–´ìš”
                            
                            #### 3. MSEì™€ RMSEëŠ”?
                            - **MSE (Mean Squared Error, í‰ê·  ì œê³± ì˜¤ì°¨)**
                              - ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œê°’ì˜ ì°¨ì´(ì˜¤ì°¨)ë¥¼ ì œê³±í•œ ê²ƒì˜ í‰ê· ì´ì—ìš”
                              - **ì‘ì„ìˆ˜ë¡**: ëª¨ë¸ì˜ ì˜ˆì¸¡ì´ ë” ì •í™•í•˜ë‹¤ëŠ” ì˜ë¯¸ì˜ˆìš”
                              - **í´ìˆ˜ë¡**: ëª¨ë¸ì˜ ì˜ˆì¸¡ì´ ë¶€ì •í™•í•˜ë‹¤ëŠ” ì˜ë¯¸ì˜ˆìš”
                              - ë‹¨ì : ë‹¨ìœ„ê°€ ì œê³±ë˜ì–´ ìˆì–´ì„œ ì§ê´€ì ì´ì§€ ì•Šì•„ìš”
                            
                            - **RMSE (Root Mean Squared Error, í‰ê·  ì œê³±ê·¼ ì˜¤ì°¨)**
                              - MSEì˜ ì œê³±ê·¼ì„ ì·¨í•œ ê°’ì´ì—ìš”
                              - **ì‘ì„ìˆ˜ë¡**: ëª¨ë¸ì˜ ì˜ˆì¸¡ì´ ë” ì •í™•í•˜ë‹¤ëŠ” ì˜ë¯¸ì˜ˆìš”
                              - **í´ìˆ˜ë¡**: ëª¨ë¸ì˜ ì˜ˆì¸¡ì´ ë¶€ì •í™•í•˜ë‹¤ëŠ” ì˜ë¯¸ì˜ˆìš”
                              - ì¥ì : ì›ë˜ ë°ì´í„°ì™€ ê°™ì€ ë‹¨ìœ„ë¼ì„œ ì§ê´€ì ì´ì—ìš”
                              - ì˜ˆ: RMSEê°€ 5ë¼ë©´ â†’ ì˜ˆì¸¡ê°’ì´ ì‹¤ì œê°’ê³¼ í‰ê· ì ìœ¼ë¡œ 5ë‹¨ìœ„ ì •ë„ ì°¨ì´ê°€ ë‚œë‹¤ëŠ” ì˜ë¯¸ì˜ˆìš”
                            
                            #### 4. íšŒê·€ ë°©ì •ì‹ í™œìš©ë²•
                            - ë°©ì •ì‹ì„ ë³´ë©´ ê° ë³€ìˆ˜ê°€ ì–¼ë§ˆë‚˜ ì˜í–¥ì„ ì£¼ëŠ”ì§€ ì•Œ ìˆ˜ ìˆì–´ìš”
                            - ì˜ˆ: ë³€ìˆ˜ Aê°€ 10ì´ê³  ë³€ìˆ˜ Bê°€ 5ì¼ ë•Œ ì˜ˆì¸¡ê°’ì€?
                              1. ë°©ì •ì‹ì— ìˆ«ìë¥¼ ë„£ì–´ì„œ ê³„ì‚°í•˜ë©´ ë¼ìš”
                              2. ì–‘ìˆ˜ ê³„ìˆ˜ë©´ ë”í•˜ê³ , ìŒìˆ˜ ê³„ìˆ˜ë©´ ë¹¼ìš”
                            
                           
                            """)
                        
                        # íšŒê·€ ê³„ìˆ˜ ë° p-value ê³„ì‚°
                        # íšŒê·€ ê³„ìˆ˜
                        coefficients = model.coef_
                        
                        # p-value ê³„ì‚°
                        n = len(X_train)
                        p = len(X_train.columns)
                        dof = n - p - 1
                        
                        # MSE ê³„ì‚°
                        mse = np.sum((y_train - model.predict(X_train)) ** 2) / dof
                        
                        # Xì˜ ê³µë¶„ì‚° í–‰ë ¬ì˜ ì—­í–‰ë ¬
                        X_with_intercept = np.column_stack([np.ones(n), X_train])
                        
                        try:
                            # íŠ¹ì´ í–‰ë ¬ ë¬¸ì œë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•´ np.linalg.pinv ì‚¬ìš©
                            var_b = mse * np.linalg.pinv(np.dot(X_with_intercept.T, X_with_intercept)).diagonal()
                            
                            # í‘œì¤€ ì˜¤ì°¨
                            sd_b = np.sqrt(var_b)
                            
                            # t í†µê³„ëŸ‰
                            t_stat = coefficients / sd_b[1:]
                            
                            # p-value
                            p_values = 2 * (1 - stats.t.cdf(np.abs(t_stat), dof))
                            
                            # ê²°ê³¼ë¥¼ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜
                            regression_results = pd.DataFrame({
                                'ë³€ìˆ˜': X_train.columns,
                                'íšŒê·€ ê³„ìˆ˜': coefficients,
                                'í‘œì¤€ ì˜¤ì°¨': sd_b[1:],
                                't í†µê³„ëŸ‰': t_stat,
                                'p-value': p_values
                            })
                            
                            # p-value ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
                            regression_results = regression_results.sort_values('p-value')
                            
                            # ê²°ê³¼ í‘œì‹œ
                            st.dataframe(
                                regression_results.style.format({
                                    'íšŒê·€ ê³„ìˆ˜': '{:.4f}',
                                    'í‘œì¤€ ì˜¤ì°¨': '{:.4f}',
                                    't í†µê³„ëŸ‰': '{:.4f}',
                                    'p-value': '{:.4f}'
                                }).background_gradient(cmap='RdYlBu_r', subset=['p-value']),
                                use_container_width=True
                            )
                            
                            # íšŒê·€ ë°©ì •ì‹ í‘œì‹œ
                            st.markdown("#### íšŒê·€ ë°©ì •ì‹:")
                            equation = f"{target_col} = {model.intercept_:.4f}"
                            for i, coef in enumerate(coefficients):
                                if coef >= 0:
                                    equation += f" + {coef:.4f} Ã— {X_train.columns[i]}"
                                else:
                                    equation += f" - {abs(coef):.4f} Ã— {X_train.columns[i]}"
                            st.markdown(f"**{equation}**")
                            
                            # íšŒê·€ ëª¨ë¸ ê°€ì • ê²€ì •
                            st.markdown("#### íšŒê·€ ëª¨ë¸ ê°€ì • ê²€ì •")
                            
                            # íšŒê·€ ëª¨ë¸ ê°€ì • ê²€ì • ì„¤ëª…
                            with st.expander("ğŸ’¡ íšŒê·€ ëª¨ë¸ ê°€ì • ê²€ì • ì´í•´í•˜ê¸°", expanded=False):
                                st.markdown("""
                                ### íšŒê·€ ëª¨ë¸ ê°€ì • ê²€ì • ì´í•´í•˜ê¸°
                                
                                íšŒê·€ ë¶„ì„ì€ ì„¸ ê°€ì§€ ì£¼ìš” ê°€ì •ì„ ë§Œì¡±í•´ì•¼ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤:
                                
                                1. **ì •ê·œì„±(Normality)**
                                   - ì”ì°¨(ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œê°’ì˜ ì°¨ì´)ê°€ ì •ê·œë¶„í¬ë¥¼ ë”°ë¼ì•¼ í•©ë‹ˆë‹¤
                                   - ì´ëŠ” í†µê³„ì  ì¶”ë¡ ì˜ ìœ íš¨ì„±ì„ ë³´ì¥í•©ë‹ˆë‹¤
                                
                                2. **ì„ í˜•ì„±(Linearity)**
                                   - ì˜ˆì¸¡ë³€ìˆ˜ì™€ ë°˜ì‘ë³€ìˆ˜ ê°„ì˜ ê´€ê³„ê°€ ì„ í˜•ì ì´ì–´ì•¼ í•©ë‹ˆë‹¤
                                   - ì”ì°¨ê°€ ì˜ˆì¸¡ê°’ì— ëŒ€í•´ ë¬´ì‘ìœ„ë¡œ ë¶„í¬í•´ì•¼ í•©ë‹ˆë‹¤
                                
                                3. **ë“±ë¶„ì‚°ì„±(Homoscedasticity)**
                                   - ì”ì°¨ì˜ ë¶„ì‚°ì´ ëª¨ë“  ì˜ˆì¸¡ê°’ì—ì„œ ë™ì¼í•´ì•¼ í•©ë‹ˆë‹¤
                                   - ì´ëŠ” ëª¨ë¸ì˜ ì˜ˆì¸¡ì´ ëª¨ë“  ë²”ìœ„ì—ì„œ ë™ì¼í•œ ì •í™•ë„ë¥¼ ê°€ì ¸ì•¼ í•¨ì„ ì˜ë¯¸í•©ë‹ˆë‹¤
                                
                                ì•„ë˜ ê·¸ë˜í”„ë“¤ì„ í†µí•´ ì´ëŸ¬í•œ ê°€ì •ë“¤ì´ ë§Œì¡±ë˜ëŠ”ì§€ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
                                """)
                            
                            # 1. ì •ê·œì„± ê²€ì • (ì”ì°¨ì˜ ì •ê·œì„±)
                            residuals = y_train - model.predict(X_train)
                            _, p_value = stats.normaltest(residuals)
                            
                            col1, col2 = st.columns(2)
                            with col1:
                                # ì •ê·œì„± ê²€ì • ê²°ê³¼
                                st.markdown("**1. ì”ì°¨ì˜ ì •ê·œì„± ê²€ì •**")
                                if p_value < 0.05:
                                    st.warning(f"ì”ì°¨ê°€ ì •ê·œë¶„í¬ë¥¼ ë”°ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤ (p-value: {p_value:.4f})")
                                else:
                                    st.success(f"ì”ì°¨ê°€ ì •ê·œë¶„í¬ë¥¼ ë”°ë¦…ë‹ˆë‹¤ (p-value: {p_value:.4f})")
                                
                                # ì •ê·œì„± ê²€ì • ì„¤ëª…
                                st.markdown("""
                                #### ì •ê·œì„± ê²€ì • ê·¸ë˜í”„ í•´ì„
                                - ì´ ê·¸ë˜í”„ëŠ” ì”ì°¨ì˜ ë¶„í¬ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤
                                - ì´ìƒì ì¸ ê²½ìš°: ì¢… ëª¨ì–‘(bell-shaped)ì˜ ëŒ€ì¹­ì ì¸ ë¶„í¬
                                - ë¹¨ê°„ìƒ‰ ì ì„ : ì •ê·œë¶„í¬ ê³¡ì„ 
                                - í•´ì„:
                                  - ë¶„í¬ê°€ ëŒ€ì¹­ì ì´ê³  ì¢… ëª¨ì–‘ì´ë©´ â†’ ì •ê·œì„± ê°€ì • ë§Œì¡±
                                  - ë¶„í¬ê°€ ë¹„ëŒ€ì¹­ì´ê±°ë‚˜ ê¼¬ë¦¬ê°€ ë‘êº¼ìš°ë©´ â†’ ì •ê·œì„± ê°€ì • ìœ„ë°˜
                                """)
                                
                                # ì”ì°¨ íˆìŠ¤í† ê·¸ë¨
                                fig_residuals = go.Figure()
                                fig_residuals.add_trace(
                                    go.Histogram(
                                        x=residuals,
                                        nbinsx=30,
                                        name='ì”ì°¨',
                                        marker_color='#3498db'
                                    )
                                )
                                
                                # ì •ê·œë¶„í¬ ê³¡ì„  ì¶”ê°€
                                x_range = np.linspace(min(residuals), max(residuals), 100)
                                y_range = stats.norm.pdf(x_range, np.mean(residuals), np.std(residuals))
                                fig_residuals.add_trace(
                                    go.Scatter(
                                        x=x_range,
                                        y=y_range,
                                        mode='lines',
                                        name='ì •ê·œë¶„í¬',
                                        line=dict(color='red', dash='dash')
                                    )
                                )
                                
                                fig_residuals.update_layout(
                                    title='ì”ì°¨ ë¶„í¬',
                                    xaxis_title='ì”ì°¨',
                                    yaxis_title='ë¹ˆë„',
                                    height=300
                                )
                                st.plotly_chart(fig_residuals, use_container_width=True)
                            
                            with col2:
                                # 2. ì„ í˜•ì„± ê²€ì • (ì”ì°¨ vs ì˜ˆì¸¡ê°’)
                                st.markdown("**2. ì„ í˜•ì„± ê²€ì •**")
                                
                                # ì„ í˜•ì„± ê²€ì • ì„¤ëª…
                                st.markdown("""
                                #### ì„ í˜•ì„± ê²€ì • ê·¸ë˜í”„ í•´ì„
                                - ì´ ê·¸ë˜í”„ëŠ” ì˜ˆì¸¡ê°’ê³¼ ì”ì°¨ì˜ ê´€ê³„ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤
                                - ì´ìƒì ì¸ ê²½ìš°: ì ë“¤ì´ ë¬´ì‘ìœ„ë¡œ ë¶„í¬í•˜ê³  íŒ¨í„´ì´ ì—†ì–´ì•¼ í•¨
                                - ë¹¨ê°„ìƒ‰ ì ì„ : 0ì„  (ì”ì°¨ê°€ 0ì¸ ê¸°ì¤€ì„ )
                                - í•´ì„:
                                  - ì ë“¤ì´ ë¬´ì‘ìœ„ë¡œ ë¶„í¬í•˜ë©´ â†’ ì„ í˜•ì„± ê°€ì • ë§Œì¡±
                                  - ì ë“¤ì´ íŒ¨í„´ì„ ë³´ì´ë©´ â†’ ì„ í˜•ì„± ê°€ì • ìœ„ë°˜
                                  - ê³¡ì„ í˜• íŒ¨í„´ì´ ë³´ì´ë©´ â†’ ë¹„ì„ í˜• ê´€ê³„ ì¡´ì¬
                                """)
                                
                                # ì”ì°¨ vs ì˜ˆì¸¡ê°’ ì‚°ì ë„
                                fig_linearity = go.Figure()
                                fig_linearity.add_trace(
                                    go.Scatter(
                                        x=model.predict(X_train),
                                        y=residuals,
                                        mode='markers',
                                        marker=dict(color='#3498db', size=8, opacity=0.6),
                                        name='ì”ì°¨ vs ì˜ˆì¸¡ê°’'
                                    )
                                )
                                
                                # 0ì„  ì¶”ê°€
                                fig_linearity.add_shape(
                                    type="line",
                                    x0=min(model.predict(X_train)),
                                    y0=0,
                                    x1=max(model.predict(X_train)),
                                    y1=0,
                                    line=dict(color="red", width=1, dash="dash")
                                )
                                
                                fig_linearity.update_layout(
                                    title='ì”ì°¨ vs ì˜ˆì¸¡ê°’',
                                    xaxis_title='ì˜ˆì¸¡ê°’',
                                    yaxis_title='ì”ì°¨',
                                    height=300
                                )
                                st.plotly_chart(fig_linearity, use_container_width=True)
                            
                            # 3. ë“±ë¶„ì‚°ì„± ê²€ì •
                            st.markdown("**3. ë“±ë¶„ì‚°ì„± ê²€ì •**")
                            
                            # ë“±ë¶„ì‚°ì„± ê²€ì • ì„¤ëª…
                            st.markdown("""
                            #### ë“±ë¶„ì‚°ì„± ê²€ì • ê·¸ë˜í”„ í•´ì„
                            - ì´ ê·¸ë˜í”„ëŠ” ì˜ˆì¸¡ê°’ê³¼ ì”ì°¨ì˜ ì ˆëŒ€ê°’ ê´€ê³„ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤
                            - ì´ìƒì ì¸ ê²½ìš°: ì ë“¤ì´ ë¬´ì‘ìœ„ë¡œ ë¶„í¬í•˜ê³  íŒ¨í„´ì´ ì—†ì–´ì•¼ í•¨
                            - í•´ì„:
                              - ì ë“¤ì´ ë¬´ì‘ìœ„ë¡œ ë¶„í¬í•˜ë©´ â†’ ë“±ë¶„ì‚°ì„± ê°€ì • ë§Œì¡±
                              - ì ë“¤ì´ ê¹”ë•Œê¸° ëª¨ì–‘ì´ë‚˜ ë‹¤ë¥¸ íŒ¨í„´ì„ ë³´ì´ë©´ â†’ ë“±ë¶„ì‚°ì„± ê°€ì • ìœ„ë°˜
                              - ì”ì°¨ì˜ í¬ê¸°ê°€ ì˜ˆì¸¡ê°’ì— ë”°ë¼ ë³€ë©´ â†’ ì´ë¶„ì‚°ì„±(heteroscedasticity) ë¬¸ì œ
                            """)
                            
                            # ì”ì°¨ì˜ ì ˆëŒ€ê°’ vs ì˜ˆì¸¡ê°’
                            fig_homoscedasticity = go.Figure()
                            fig_homoscedasticity.add_trace(
                                go.Scatter(
                                    x=model.predict(X_train),
                                    y=np.abs(residuals),
                                    mode='markers',
                                    marker=dict(color='#3498db', size=8, opacity=0.6),
                                    name='|ì”ì°¨| vs ì˜ˆì¸¡ê°’'
                                )
                            )
                            
                            fig_homoscedasticity.update_layout(
                                title='|ì”ì°¨| vs ì˜ˆì¸¡ê°’ (ë“±ë¶„ì‚°ì„± ê²€ì •)',
                                xaxis_title='ì˜ˆì¸¡ê°’',
                                yaxis_title='|ì”ì°¨|',
                                height=300
                            )
                            st.plotly_chart(fig_homoscedasticity, use_container_width=True)
                            
                        except np.linalg.LinAlgError:
                            st.error("ì„ í˜• íšŒê·€ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì„ íƒí•œ ë³€ìˆ˜ë“¤ ê°„ì— ê°•í•œ ìƒê´€ê´€ê³„ê°€ ìˆì–´ ë¶„ì„ì´ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤. ë‹¤ë¥¸ ë³€ìˆ˜ ì¡°í•©ì„ ì„ íƒí•´ë³´ì„¸ìš”.")
                            st.info("ë‹¤ì¤‘ê³µì„ ì„± ë¬¸ì œê°€ ë°œìƒí–ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë³€ìˆ˜ë“¤ ê°„ì˜ ìƒê´€ê´€ê³„ë¥¼ í™•ì¸í•˜ê³  ì¤‘ë³µëœ ì •ë³´ë¥¼ ì œê³µí•˜ëŠ” ë³€ìˆ˜ë¥¼ ì œê±°í•´ë³´ì„¸ìš”.")
                            
                            # ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ í‘œì‹œ
                            st.subheader("ë³€ìˆ˜ ê°„ ìƒê´€ê´€ê³„")
                            corr_matrix = X_train.corr()
                            fig, ax = plt.subplots(figsize=(10, 8))
                            sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', ax=ax)
                            st.pyplot(fig)
                    
                    # ëª¨ë¸ ë° íŠ¹ì„± ì €ì¥
                    st.session_state.model = model
                    st.session_state.model_features = top_indices.tolist()
                    st.session_state.remove_outliers = remove_outliers
                    st.session_state.apply_scaling = apply_scaling
                    st.session_state.model_type = model_type
                    
                    if remove_outliers:
                        if outlier_method == "Z-ì ìˆ˜":
                            st.session_state.outlier_method = "zscore"
                            st.session_state.outlier_param = z_threshold
                        else:
                            st.session_state.outlier_method = "iqr"
                            st.session_state.outlier_param = iqr_multiplier
                    
                    # ì‹¤ì œê°’-ì˜ˆì¸¡ê°’ ë¹„êµ ê·¸ë˜í”„ (Plotlyë¡œ ë³€ê²½)
                    fig_compare = go.Figure()

                    # ì‚°ì ë„ ì¶”ê°€
                    fig_compare.add_trace(
                        go.Scatter(
                            x=y_test,
                            y=y_pred,
                            mode='markers',
                            marker=dict(
                                size=8,
                                color='rgba(0, 123, 255, 0.7)',
                                line=dict(
                                    color='rgba(0, 123, 255, 1.0)',
                                    width=1
                                )
                            ),
                            name='ì˜ˆì¸¡ê°’',
                            hovertemplate='ì‹¤ì œê°’: %{x:.4f}<br>ì˜ˆì¸¡ê°’: %{y:.4f}<extra></extra>'
                        )
                    )

                    # ì´ìƒì ì¸ ì˜ˆì¸¡ì„  (ëŒ€ê°ì„ ) ì¶”ê°€
                    min_val = min(min(y_test), min(y_pred))
                    max_val = max(max(y_test), max(y_pred))
                    fig_compare.add_trace(
                        go.Scatter(
                            x=[min_val, max_val],
                            y=[min_val, max_val],
                            mode='lines',
                            line=dict(color='red', dash='dash'),
                            name='ì´ìƒì ì¸ ì˜ˆì¸¡'
                        )
                    )

                    # ë ˆì´ì•„ì›ƒ ì„¤ì •
                    fig_compare.update_layout(
                        title='ì‹¤ì œê°’ vs ì˜ˆì¸¡ê°’',
                        xaxis_title='ì‹¤ì œê°’',
                        yaxis_title='ì˜ˆì¸¡ê°’',
                        height=500,
                        width=700,
                        showlegend=True,
                        hovermode='closest'
                    )

                    # ì¶• ë²”ìœ„ë¥¼ ë™ì¼í•˜ê²Œ ì„¤ì •
                    overall_min = min(min_val, min_val)
                    overall_max = max(max_val, max_val)
                    padding = (overall_max - overall_min) * 0.05
                    fig_compare.update_xaxes(range=[overall_min - padding, overall_max + padding])
                    fig_compare.update_yaxes(range=[overall_min - padding, overall_max + padding])

                    # ê·¸ë¦¬ë“œ ì¶”ê°€
                    fig_compare.update_layout(
                        xaxis=dict(
                            showgrid=True,
                            gridwidth=1,
                            gridcolor='LightGrey'
                        ),
                        yaxis=dict(
                            showgrid=True,
                            gridwidth=1,
                            gridcolor='LightGrey'
                        )
                    )

                    # ê·¸ë˜í”„ í‘œì‹œ
                    display_plotly_centered(fig_compare)
                    
                    # ë³€ìˆ˜ ì¤‘ìš”ë„ ì‹œê°í™”
                    if model_type in ["RandomForest", "XGBoost"]:
                        # ëœë¤ í¬ë ˆìŠ¤íŠ¸ì™€ XGBoostì˜ ë³€ìˆ˜ ì¤‘ìš”ë„
                        feature_importance = model.feature_importances_
                        
                        # ë³€ìˆ˜ ì¤‘ìš”ë„ë¥¼ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜
                        feature_importance_df = pd.DataFrame({
                            'Feature': X_train.columns,
                            'Importance': feature_importance
                        })

                        # ì¤‘ìš”ë„ ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
                        feature_importance_df = feature_importance_df.sort_values('Importance', ascending=False)

                        # Plotly ê·¸ë˜í”„ ìƒì„±
                        fig_importance = go.Figure()

                        # ë°” ì°¨íŠ¸ ì¶”ê°€ (ë‚¨ìƒ‰ìœ¼ë¡œ ë³€ê²½)
                        fig_importance.add_trace(
                            go.Bar(
                                y=feature_importance_df['Feature'],
                                x=feature_importance_df['Importance'],
                                orientation='h',
                                marker_color='#3498db',  # ë‚¨ìƒ‰ìœ¼ë¡œ ë³€ê²½
                                text=[f'{val:.4f}' for val in feature_importance_df['Importance']],
                                textposition='outside',
                                hovertemplate='%{y}: %{x:.4f}<extra></extra>'
                            )
                        )

                        # ë ˆì´ì•„ì›ƒ ì„¤ì •
                        fig_importance.update_layout(
                            title='ëª¨ë¸ì˜ ì „ë°˜ì ì¸ ë³€ìˆ˜ ì¤‘ìš”ë„',
                            xaxis_title='ì¤‘ìš”ë„',
                            yaxis_title='ë³€ìˆ˜',
                            height=500,
                            margin=dict(l=20, r=20, t=40, b=20),
                            xaxis=dict(
                                range=[0, max(feature_importance_df['Importance']) * 1.1],  # 0ë¶€í„° ì‹œì‘í•˜ë„ë¡ ìˆ˜ì •
                                showgrid=True,
                                gridwidth=1,
                                gridcolor='LightGrey'
                            ),
                            yaxis=dict(
                                autorange='reversed'  # ì¤‘ìš”ë„ê°€ ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬
                            )
                        )

                        # ê·¸ë˜í”„ í‘œì‹œ
                        st.subheader("ëª¨ë¸ì˜ ì „ë°˜ì ì¸ ë³€ìˆ˜ ì¤‘ìš”ë„")
                        display_plotly_centered(fig_importance)
                    
                    # ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ ë©”ì‹œì§€ì™€ ì‹œë®¬ë ˆì´ì…˜ ë²„íŠ¼
                    st.success("ëª¨ë¸ í›ˆë ¨ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        
        with tab2:
            st.write("### ì‹œë®¬ë ˆì´ì…˜")
            
            if 'model' in st.session_state and 'model_features' in st.session_state:
                # ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ ì„ íƒ
                simulation_mode = st.radio(
                    "ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ:",
                    ["ìˆ˜ë™ ì‹œë®¬ë ˆì´ì…˜", "ìµœì í™” ì‹œë®¬ë ˆì´ì…˜"],
                    horizontal=True
                )
                
                if simulation_mode == "ìˆ˜ë™ ì‹œë®¬ë ˆì´ì…˜":
                    st.write("ì•„ë˜ ë³€ìˆ˜ë“¤ì˜ ê°’ì„ ì¡°ì •í•˜ì—¬ ì˜ˆì¸¡í•´ë³´ì„¸ìš”:")
                    
                    # ì…ë ¥ ìœ„ì ¯ ìƒì„±
                    input_values = {}
                    for feature in st.session_state.model_features:
                        min_val = float(numeric_data[feature].min())
                        max_val = float(numeric_data[feature].max())
                        mean_val = float(numeric_data[feature].mean())
                        std_val = float(numeric_data[feature].std())
                        
                        # ìŠ¬ë¼ì´ë” ìƒì„±
                        input_values[feature] = st.slider(
                            f"{feature} (í‰ê· : {mean_val:.2f}, í‘œì¤€í¸ì°¨: {std_val:.2f})",
                            min_val,
                            max_val,
                            mean_val,
                            step=(max_val-min_val)/100
                        )
                    
                    # ì˜ˆì¸¡ ìˆ˜í–‰ ë²„íŠ¼
                    if st.button("ì˜ˆì¸¡ ìˆ˜í–‰"):
                        with st.spinner("ì˜ˆì¸¡ ì¤‘..."):
                            # ì…ë ¥ê°’ìœ¼ë¡œ ë°ì´í„°í”„ë ˆì„ ìƒì„±
                            input_df = pd.DataFrame([input_values])
                            
                            # ìŠ¤ì¼€ì¼ë§ ì ìš© (í•„ìš”í•œ ê²½ìš°)
                            if 'apply_scaling' in st.session_state and st.session_state.apply_scaling:
                                input_scaled = st.session_state.scaler.transform(input_df)
                                input_scaled_df = pd.DataFrame(input_scaled, columns=input_df.columns)
                                prediction = st.session_state.model.predict(input_scaled_df)[0]
                            else:
                                prediction = st.session_state.model.predict(input_df)[0]
                            
                            # ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì„¸ì…˜ ìƒíƒœì— ì €ì¥ (ì§€ì†ì„± ìœ ì§€)
                            st.session_state.last_prediction = prediction
                            st.session_state.last_input_values = input_values.copy()
                            
                            # íƒ€ê²Ÿ í†µê³„ ì •ë³´ ì €ì¥
                            st.session_state.target_mean = numeric_data[target_col].mean()
                            st.session_state.target_min = numeric_data[target_col].min()
                            st.session_state.target_max = numeric_data[target_col].max()
                
                else:  # ìµœì í™” ì‹œë®¬ë ˆì´ì…˜
                    st.write("### ìµœì í™” ì‹œë®¬ë ˆì´ì…˜")
                    st.write("ëª©í‘œê°’ì„ ì„¤ì •í•˜ê³  ìµœì ì˜ ë³€ìˆ˜ ì¡°í•©ì„ ì°¾ì•„ë³´ì„¸ìš”.")
                    
                    # ëª©í‘œê°’ ì„¤ì •
                    target_value = st.number_input(
                        f"ëª©í‘œ {target_col} ê°’:",
                        min_value=float(numeric_data[target_col].min()),
                        max_value=float(numeric_data[target_col].max()),
                        value=float(numeric_data[target_col].mean()),
                        step=0.1
                    )
                    
                    # ìµœì í™” ë°©ë²• ì„ íƒ
                    optimization_method = st.radio(
                        "ìµœì í™” ë°©ë²•:",
                        ["ëœë¤ ì„œì¹˜"],
                        horizontal=True
                    )
                    
                    # ëœë¤ ì„œì¹˜ ì„¤ëª… ì¶”ê°€
                    with st.expander("ğŸ’¡ ëœë¤ ì„œì¹˜(Random Search)ë€?", expanded=False):
                        st.markdown("""
                        ### ëœë¤ ì„œì¹˜(Random Search) ì´í•´í•˜ê¸°
                        
                        ëœë¤ ì„œì¹˜ëŠ” ìµœì í™” ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•œ íš¨ìœ¨ì ì¸ ë°©ë²•ì…ë‹ˆë‹¤:
                        
                        #### 1. ê¸°ë³¸ ê°œë…
                        - **ëœë¤ ì„œì¹˜**: ë³€ìˆ˜ì˜ ê°€ëŠ¥í•œ ê°’ ë²”ìœ„ ë‚´ì—ì„œ ë¬´ì‘ìœ„ë¡œ ê°’ì„ ì„ íƒí•˜ì—¬ ìµœì ì˜ ì¡°í•©ì„ ì°¾ëŠ” ë°©ë²•
                        - **ì¥ì **: 
                          - ê·¸ë¦¬ë“œ ì„œì¹˜ë³´ë‹¤ í›¨ì”¬ ë¹ ë¥¸ ì†ë„
                          - ë” ë„“ì€ íƒìƒ‰ ë²”ìœ„ ì»¤ë²„
                          - ì§€ì—­ ìµœì í•´ì— ëœ ë¯¼ê°
                        
                        #### 2. ì‘ë™ ë°©ì‹
                        1. ê° ë³€ìˆ˜ì— ëŒ€í•´ ì„¤ì •ëœ ë²”ìœ„ ë‚´ì—ì„œ ë¬´ì‘ìœ„ë¡œ ê°’ì„ ì„ íƒ
                        2. ì„ íƒëœ ê°’ë“¤ë¡œ ì˜ˆì¸¡ì„ ìˆ˜í–‰
                        3. ëª©í‘œê°’ê³¼ ê°€ì¥ ê°€ê¹Œìš´ ê²°ê³¼ë¥¼ ì°¾ì„ ë•Œê¹Œì§€ ë°˜ë³µ
                        
                        #### 3. ê·¸ë¦¬ë“œ ì„œì¹˜ì™€ì˜ ì°¨ì´ì 
                        - **ê·¸ë¦¬ë“œ ì„œì¹˜**: ëª¨ë“  ê°€ëŠ¥í•œ ì¡°í•©ì„ ì²´ê³„ì ìœ¼ë¡œ ì‹œë„ (ëŠë¦¼)
                        - **ëœë¤ ì„œì¹˜**: ë¬´ì‘ìœ„ë¡œ ì„ íƒëœ ì¡°í•©ë§Œ ì‹œë„ (ë¹ ë¦„)
                        
                        #### 4. í™œìš© ì‹œ ê³ ë ¤ì‚¬í•­
                        - ì‹œë„ íšŸìˆ˜ë¥¼ ëŠ˜ë¦¬ë©´ ë” ì¢‹ì€ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆìŒ
                        - ë³€ìˆ˜ì˜ ë²”ìœ„ë¥¼ ì ì ˆíˆ ì„¤ì •í•˜ëŠ” ê²ƒì´ ì¤‘ìš”
                        - ëª©í‘œê°’ì— ë„ë‹¬í•˜ì§€ ëª»í•  ê²½ìš° ë²”ìœ„ ì¡°ì • í•„ìš”
                        """)
                    
                    # ìµœì í™” ë²”ìœ„ ì„¤ì •
                    st.write("#### ë³€ìˆ˜ ë²”ìœ„ ì„¤ì •")
                    variable_ranges = {}
                    
                    for feature in st.session_state.model_features:
                        min_val = float(numeric_data[feature].min())
                        max_val = float(numeric_data[feature].max())
                        mean_val = float(numeric_data[feature].mean())
                        
                        col1, col2 = st.columns(2)
                        with col1:
                            variable_ranges[feature] = {
                                'min': st.number_input(
                                    f"{feature} ìµœì†Œê°’:",
                                    min_value=min_val,
                                    max_value=mean_val,
                                    value=min_val,
                                    step=(mean_val-min_val)/20
                                )
                            }
                        with col2:
                            variable_ranges[feature]['max'] = st.number_input(
                                f"{feature} ìµœëŒ€ê°’:",
                                min_value=mean_val,
                                max_value=max_val,
                                value=max_val,
                                step=(max_val-mean_val)/20
                            )
                    
                    # ìµœì í™” ë²„íŠ¼
                    if st.button("ìµœì í™” ìˆ˜í–‰"):
                        with st.spinner("ìµœì í™” ì¤‘..."):
                            # ìµœì í™” ìˆ˜í–‰
                            best_input_values = {}
                            best_prediction = None
                            min_diff = float('inf')
                            
                            # ëœë¤ ì„œì¹˜ íŒŒë¼ë¯¸í„°
                            n_iterations = 1000  # ì‹œë„í•  ì¡°í•©ì˜ ìˆ˜
                            
                            # ì§„í–‰ ìƒí™© í‘œì‹œ
                            progress_bar = st.progress(0)
                            status_text = st.empty()
                            
                            # ëœë¤ ì„œì¹˜ ìˆ˜í–‰
                            for i in range(n_iterations):
                                # ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸
                                progress = (i + 1) / n_iterations
                                progress_bar.progress(progress)
                                status_text.text(f"ì§„í–‰ ì¤‘: {i+1}/{n_iterations} ì¡°í•© ì‹œë„ ì¤‘...")
                                
                                # ëœë¤ ì…ë ¥ê°’ ìƒì„±
                                current_input = {}
                                for feature in st.session_state.model_features:
                                    min_val = variable_ranges[feature]['min']
                                    max_val = variable_ranges[feature]['max']
                                    current_input[feature] = np.random.uniform(min_val, max_val)
                                
                                input_df = pd.DataFrame([current_input])
                                
                                # ìŠ¤ì¼€ì¼ë§ ì ìš© (í•„ìš”í•œ ê²½ìš°)
                                if 'apply_scaling' in st.session_state and st.session_state.apply_scaling:
                                    input_scaled = st.session_state.scaler.transform(input_df)
                                    input_scaled_df = pd.DataFrame(input_scaled, columns=input_df.columns)
                                    prediction = st.session_state.model.predict(input_scaled_df)[0]
                                else:
                                    prediction = st.session_state.model.predict(input_df)[0]
                                
                                # ëª©í‘œê°’ê³¼ì˜ ì°¨ì´ ê³„ì‚°
                                diff = abs(prediction - target_value)
                                
                                # ìµœì  ì¡°í•© ì—…ë°ì´íŠ¸
                                if diff < min_diff:
                                    min_diff = diff
                                    best_prediction = prediction
                                    best_input_values = current_input.copy()
                            
                            # ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸ ì™„ë£Œ
                            progress_bar.progress(1.0)
                            status_text.text("ìµœì í™” ì™„ë£Œ!")
                            
                            # ìµœì í™” ê²°ê³¼ ì €ì¥
                            st.session_state.last_prediction = best_prediction
                            st.session_state.last_input_values = best_input_values
                            
                            # íƒ€ê²Ÿ í†µê³„ ì •ë³´ ì €ì¥
                            st.session_state.target_mean = numeric_data[target_col].mean()
                            st.session_state.target_min = numeric_data[target_col].min()
                            st.session_state.target_max = numeric_data[target_col].max()
                
                # ì˜ˆì¸¡ ê²°ê³¼ê°€ ìˆìœ¼ë©´ í•­ìƒ í‘œì‹œ (ë³€ìˆ˜ë³„ ê¸°ì—¬ë„ ë¶„ì„ê³¼ ë¬´ê´€í•˜ê²Œ ìœ ì§€)
                if 'last_prediction' in st.session_state:
                    prediction = st.session_state.last_prediction
                    target_mean = st.session_state.target_mean
                    target_min = st.session_state.target_min
                    target_max = st.session_state.target_max
                    
                    # ì˜ˆì¸¡ ê²°ê³¼ í‘œì‹œ
                    st.success(f"### ì˜ˆì¸¡ëœ {target_col}: {prediction:.4f}")
                    
                    # ì¶”ê°€ ì •ë³´: í‰ê·  ë° ë²”ìœ„ì™€ ë¹„êµ
                    col1, col2, col3 = st.columns(3)
                    col1.metric("í‰ê·  ëŒ€ë¹„", f"{(prediction - target_mean):.4f}", 
                                f"{((prediction - target_mean) / target_mean * 100):.2f}%")
                    col2.metric("ìµœì†Œê°’", f"{target_min:.4f}")
                    col3.metric("ìµœëŒ€ê°’", f"{target_max:.4f}")
                    
                    # ìµœì í™” ëª¨ë“œì¸ ê²½ìš° ëª©í‘œê°’ê³¼ì˜ ì°¨ì´ í‘œì‹œ
                    if simulation_mode == "ìµœì í™” ì‹œë®¬ë ˆì´ì…˜":
                        st.metric("ëª©í‘œê°’ê³¼ì˜ ì°¨ì´", f"{abs(prediction - target_value):.4f}")
                    
                    # ìµœì  ë³€ìˆ˜ ê°’ í‘œì‹œ
                    st.write("#### ìµœì  ë³€ìˆ˜ ê°’:")
                    optimal_values_df = pd.DataFrame({
                        'ë³€ìˆ˜': list(st.session_state.last_input_values.keys()),
                        'ê°’': list(st.session_state.last_input_values.values())
                    })
                    st.dataframe(optimal_values_df, use_container_width=True)

                    # ì›ì¸ ë¶„ì„ ê·¸ë˜í”„ ì¶”ê°€
                    st.write("### ì›ì¸ ë¶„ì„")
                    
                    # ì„¤ëª… ë¶€ë¶„ì„ ë¨¼ì € í‘œì‹œ
                    with st.expander("ğŸ’¡ ì›ì¸ ë¶„ì„ ê·¸ë˜í”„ ì´í•´í•˜ê¸°", expanded=False):
                        st.markdown("""
                        ### ì›ì¸ ë¶„ì„ ê·¸ë˜í”„ ì‰½ê²Œ ì´í•´í•˜ê¸°
                        
                        ì´ ê·¸ë˜í”„ëŠ” ê° ë³€ìˆ˜ê°€ í˜„ì¬ ì˜ˆì¸¡ê°’ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
                        ë§ˆì¹˜ ìš”ë¦¬ì—ì„œ ê° ì¬ë£Œê°€ ìµœì¢… ë§›ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ë ¥ì„ ë³´ëŠ” ê²ƒê³¼ ê°™ìŠµë‹ˆë‹¤!
                        
                        #### 1. ë³€ìˆ˜ë³„ ê¸°ì—¬ë„ ì´í•´í•˜ê¸°
                        
                        **ê¸°ì—¬ë„ë€?**
                        - ê° ë³€ìˆ˜ê°€ ì˜ˆì¸¡ê°’ì„ ì–¼ë§ˆë‚˜ ë³€í™”ì‹œí‚¤ëŠ”ì§€ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ì§€í‘œì…ë‹ˆë‹¤
                        - ì–‘ìˆ˜: ì˜ˆì¸¡ê°’ì„ ì¦ê°€ì‹œí‚¤ëŠ” ë°©í–¥ìœ¼ë¡œ ì‘ìš© (ì˜ˆ: ì˜¨ë„ê°€ ë†’ì„ìˆ˜ë¡ ìˆ˜ìœ¨ ì¦ê°€)
                        - ìŒìˆ˜: ì˜ˆì¸¡ê°’ì„ ê°ì†Œì‹œí‚¤ëŠ” ë°©í–¥ìœ¼ë¡œ ì‘ìš© (ì˜ˆ: ì••ë ¥ì´ ë†’ì„ìˆ˜ë¡ ë¶ˆëŸ‰ë¥  ê°ì†Œ)
                        - ì ˆëŒ€ê°’ì´ í´ìˆ˜ë¡: ì˜í–¥ë ¥ì´ í¬ë‹¤ëŠ” ì˜ë¯¸ì…ë‹ˆë‹¤
                        
                        **ê¸°ì—¬ë„ í•´ì„ ì˜ˆì‹œ:**
                        - ê¸°ì—¬ë„ +0.5: ì´ ë³€ìˆ˜ê°€ í‰ê· ë³´ë‹¤ ë†’ê²Œ ì„¤ì •ë˜ì–´ ì˜ˆì¸¡ê°’ì„ 0.5ë§Œí¼ ì¦ê°€ì‹œí‚´
                        - ê¸°ì—¬ë„ -0.3: ì´ ë³€ìˆ˜ê°€ í‰ê· ë³´ë‹¤ ë‚®ê²Œ ì„¤ì •ë˜ì–´ ì˜ˆì¸¡ê°’ì„ 0.3ë§Œí¼ ê°ì†Œì‹œí‚´
                        
                        #### 2. í‰ê·  ëŒ€ë¹„ ì˜í–¥ ì´í•´í•˜ê¸°
                        
                        **í‰ê·  ëŒ€ë¹„ ì˜í–¥ì´ë€?**
                        - ê° ë³€ìˆ˜ì˜ í˜„ì¬ê°’ì´ í‰ê· ê°’ê³¼ ì–¼ë§ˆë‚˜ ì°¨ì´ë‚˜ëŠ”ì§€ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤
                        - ì–‘ìˆ˜: í‰ê· ë³´ë‹¤ ë†’ì€ ê°’ìœ¼ë¡œ ì„¤ì •ë¨
                        - ìŒìˆ˜: í‰ê· ë³´ë‹¤ ë‚®ì€ ê°’ìœ¼ë¡œ ì„¤ì •ë¨
                        - ë°±ë¶„ìœ¨(%): í‰ê·  ëŒ€ë¹„ ì–¼ë§ˆë‚˜ ì°¨ì´ë‚˜ëŠ”ì§€ë¥¼ ë°±ë¶„ìœ¨ë¡œ í‘œì‹œ
                        
                        **ì°¨ì´(%) í•´ì„ ì˜ˆì‹œ:**
                        - +20%: í‰ê· ë³´ë‹¤ 20% ë†’ì€ ê°’ìœ¼ë¡œ ì„¤ì •ë¨
                        - -15%: í‰ê· ë³´ë‹¤ 15% ë‚®ì€ ê°’ìœ¼ë¡œ ì„¤ì •ë¨
                        
                        #### 3. ê¸°ì—¬ë„ê°€ ë‚®ë”ë¼ë„ ì¤‘ìš”í•œ ì´ìœ 
                        
                        **ê¸°ì—¬ë„ê°€ ë‚®ì€ ë³€ìˆ˜ë„ ì¤‘ìš”í•œ ê²½ìš°:**
                        1. **ì„ê³„ê°’(Threshold) íš¨ê³¼**: 
                           - íŠ¹ì • ê°’ ì´í•˜/ì´ìƒì´ë©´ ê¸‰ê²©í•œ ë³€í™”ë¥¼ ì¼ìœ¼í‚¬ ìˆ˜ ìˆìŒ
                           - ì˜ˆ: ì˜¨ë„ê°€ 80Â°C ì´í•˜ë©´ ë°˜ì‘ì´ ì¼ì–´ë‚˜ì§€ ì•Šì§€ë§Œ, 80Â°C ì´ìƒì´ë©´ ê¸‰ê²©íˆ ë°˜ì‘
                        
                        2. **ìƒí˜¸ì‘ìš©(Interaction) íš¨ê³¼**: 
                           - ë‹¤ë¥¸ ë³€ìˆ˜ì™€ í•¨ê»˜ ì‘ìš©í•  ë•Œ ì¤‘ìš”í•´ì§ˆ ìˆ˜ ìˆìŒ
                           - ì˜ˆ: ì••ë ¥ê³¼ ì˜¨ë„ê°€ ëª¨ë‘ ë†’ì„ ë•Œë§Œ íŠ¹ì • íš¨ê³¼ê°€ ë°œìƒ
                        
                        3. **ì•ˆì •ì„±(Stability) ìš”ì¸**: 
                           - ë³€ë™ì´ ì‘ë”ë¼ë„ ì•ˆì •ì ì¸ ê³µì •ì„ ìœ„í•´ ì¤‘ìš”í•  ìˆ˜ ìˆìŒ
                           - ì˜ˆ: pH ê°’ì´ ì•½ê°„ë§Œ ë³€í•´ë„ í’ˆì§ˆì— í° ì˜í–¥ì„ ë¯¸ì¹  ìˆ˜ ìˆìŒ
                        
                        4. **ë¹„ìš© íš¨ìœ¨ì„±(Cost Efficiency)**: 
                           - ì¡°ì • ë¹„ìš©ì´ ë‚®ì€ ë³€ìˆ˜ë¼ë©´ ì‘ì€ ì˜í–¥ì´ë¼ë„ ì¡°ì • ê°€ì¹˜ê°€ ìˆìŒ
                           - ì˜ˆ: ì•½ê°„ì˜ ì˜¨ë„ ì¡°ì •ìœ¼ë¡œ í° íš¨ê³¼ë¥¼ ë³¼ ìˆ˜ ìˆëŠ” ê²½ìš°
                        
                        #### 4. ì›ì¸ ë¶„ì„ í™œìš© ë°©ë²•
                        
                        **ìµœì í™” ì „ëµ:**
                        - **ê¸ì •ì  ì˜í–¥ ë³€ìˆ˜**: ê¸°ì—¬ë„ê°€ í° ë³€ìˆ˜ëŠ” ë” ì„¸ë°€í•˜ê²Œ ì¡°ì •
                        - **ë¶€ì •ì  ì˜í–¥ ë³€ìˆ˜**: ê¸°ì—¬ë„ê°€ ì‘ì€ ë³€ìˆ˜ëŠ” ë²”ìœ„ë¥¼ ë„“ê²Œ ì„¤ì •
                        - **ìµœì í™” ë°©í–¥**: ê¸°ì—¬ë„ ë°©í–¥ì— ë”°ë¼ ë³€ìˆ˜ ê°’ì„ ì¡°ì •
                        
                        **ì‹¤ì œ ì ìš© ì˜ˆì‹œ:**
                        1. ê¸°ì—¬ë„ê°€ í° ë³€ìˆ˜(ì˜ˆ: +0.8)ëŠ” í˜„ì¬ ì„¤ì •ê°’ì´ ì ì ˆí•œì§€ í™•ì¸
                        2. ê¸°ì—¬ë„ê°€ ìŒìˆ˜ì¸ ë³€ìˆ˜(ì˜ˆ: -0.5)ëŠ” ê°’ì„ ì¦ê°€ì‹œì¼œ ë¶€ì •ì  ì˜í–¥ ê°ì†Œ
                        3. ê¸°ì—¬ë„ê°€ ë‚®ì€ ë³€ìˆ˜ë„ ìƒí˜¸ì‘ìš© ê°€ëŠ¥ì„±ì„ ê³ ë ¤í•˜ì—¬ ì¡°ì •
                        
                        **ì£¼ì˜ì‚¬í•­:**
                        - ê¸°ì—¬ë„ëŠ” í˜„ì¬ ì„¤ì •ê°’ ê¸°ì¤€ìœ¼ë¡œ ê³„ì‚°ë˜ë¯€ë¡œ, ë³€ìˆ˜ ê°’ì„ í¬ê²Œ ë³€ê²½í•˜ë©´ ê¸°ì—¬ë„ë„ ë³€í•  ìˆ˜ ìˆìŒ
                        - ì—¬ëŸ¬ ë³€ìˆ˜ë¥¼ ë™ì‹œì— ì¡°ì •í•  ë•ŒëŠ” ìƒí˜¸ì‘ìš© íš¨ê³¼ë¥¼ ê³ ë ¤í•´ì•¼ í•¨
                        - ì‹¤ì œ ê³µì •ì—ì„œëŠ” ë³€ìˆ˜ ê°„ ì œì•½ì¡°ê±´ì´ ìˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì´ë¥¼ ê³ ë ¤í•´ì•¼ í•¨
                        """)
                    
                    # ë³€ìˆ˜ë³„ ê¸°ì—¬ë„ ê³„ì‚°
                    contributions = {}
                    mean_values = {}
                    valid_features = []
                    
                    for feature in st.session_state.model_features:
                        try:
                            # í˜„ì¬ ê°’ì´ ìˆëŠ”ì§€ í™•ì¸
                            if feature not in st.session_state.last_input_values:
                                st.warning(f"'{feature}' ë³€ìˆ˜ê°€ ì…ë ¥ê°’ì— ì—†ì–´ ê¸°ì—¬ë„ ê³„ì‚°ì—ì„œ ì œì™¸ë©ë‹ˆë‹¤.")
                                continue
                            
                            current_value = st.session_state.last_input_values[feature]
                            mean_value = numeric_data[feature].mean()
                            mean_values[feature] = mean_value
                            valid_features.append(feature)
                            
                            # ë³€ìˆ˜ì˜ ì˜í–¥ë ¥ ê³„ì‚°
                            if st.session_state.model_type == "ì„ í˜• íšŒê·€":
                                # ì„ í˜• íšŒê·€ì˜ ê²½ìš° ê³„ìˆ˜ë¥¼ ì‚¬ìš©
                                coef = st.session_state.model.coef_[list(st.session_state.model_features).index(feature)]
                                contribution = coef * (current_value - mean_value)
                            else:
                                # RandomForestë‚˜ XGBoostì˜ ê²½ìš° feature_importances_ë¥¼ ì‚¬ìš©
                                importance = st.session_state.model.feature_importances_[list(st.session_state.model_features).index(feature)]
                                contribution = importance * (current_value - mean_value) / mean_value
                            
                            contributions[feature] = contribution
                        except Exception as e:
                            st.warning(f"'{feature}' ë³€ìˆ˜ì˜ ê¸°ì—¬ë„ ê³„ì‚° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                            continue
                    
                    if not contributions:
                        st.error("ê¸°ì—¬ë„ë¥¼ ê³„ì‚°í•  ìˆ˜ ìˆëŠ” ë³€ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    else:
                        # ê¸°ì—¬ë„ë¥¼ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜
                        contribution_df = pd.DataFrame({
                            'ë³€ìˆ˜': list(contributions.keys()),
                            'ê¸°ì—¬ë„': list(contributions.values()),
                            'í‰ê·  ëŒ€ë¹„': [st.session_state.last_input_values[f] - mean_values[f] for f in contributions.keys()]
                        })

                        # ê¸°ì—¬ë„ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
                        contribution_df = contribution_df.sort_values('ê¸°ì—¬ë„', key=abs, ascending=False)

                        # Plotly ê·¸ë˜í”„ ìƒì„±
                        fig_contribution = go.Figure()

                        # ê¸°ì—¬ë„ ë°” ì°¨íŠ¸
                        fig_contribution.add_trace(
                            go.Bar(
                                y=contribution_df['ë³€ìˆ˜'],
                                x=contribution_df['ê¸°ì—¬ë„'],
                                orientation='h',
                                marker_color=np.where(contribution_df['ê¸°ì—¬ë„'] >= 0, '#3498db', '#e74c3c'),
                                text=[f'{val:.4f}' for val in contribution_df['ê¸°ì—¬ë„']],
                                textposition='outside',
                                name='ê¸°ì—¬ë„',
                                hovertemplate='%{y}: %{x:.4f}<extra></extra>'
                            )
                        )

                        # ë ˆì´ì•„ì›ƒ ì„¤ì •
                        fig_contribution.update_layout(
                            title='ë³€ìˆ˜ë³„ ê¸°ì—¬ë„ ë¶„ì„',
                            xaxis_title='ê¸°ì—¬ë„',
                            yaxis_title='ë³€ìˆ˜',
                            height=500,
                            margin=dict(l=20, r=20, t=40, b=20),
                            showlegend=False,
                            yaxis=dict(
                                autorange='reversed'  # ê¸°ì—¬ë„ê°€ í° ìˆœìœ¼ë¡œ ì •ë ¬
                            )
                        )

                        # ê·¸ë˜í”„ í‘œì‹œ
                        display_plotly_centered(fig_contribution)

                        # í‰ê·  ëŒ€ë¹„ ì˜í–¥ ë¶„ì„
                        st.write("#### í‰ê·  ëŒ€ë¹„ ë³€ìˆ˜ ì˜í–¥")
                        influence_df = pd.DataFrame({
                            'ë³€ìˆ˜': contribution_df['ë³€ìˆ˜'],
                            'í˜„ì¬ê°’': [st.session_state.last_input_values[f] for f in contribution_df['ë³€ìˆ˜']],
                            'í‰ê· ê°’': [mean_values[f] for f in contribution_df['ë³€ìˆ˜']],
                            'ì°¨ì´': [st.session_state.last_input_values[f] - mean_values[f] for f in contribution_df['ë³€ìˆ˜']],
                            'ì°¨ì´(%)': [(st.session_state.last_input_values[f] - mean_values[f]) / mean_values[f] * 100 for f in contribution_df['ë³€ìˆ˜']]
                        })

                        # ìŠ¤íƒ€ì¼ ì ìš©
                        st.dataframe(
                            influence_df.style.format({
                                'í˜„ì¬ê°’': '{:.4f}',
                                'í‰ê· ê°’': '{:.4f}',
                                'ì°¨ì´': '{:.4f}',
                                'ì°¨ì´(%)': '{:.2f}%'
                            }).background_gradient(cmap='RdYlBu_r', subset=['ì°¨ì´(%)']),
                            use_container_width=True
                        )
            else:
                st.info("ë¨¼ì € ëª¨ë¸ì„ í›ˆë ¨í•´ì£¼ì„¸ìš”.")
    else:
        st.error(f"íƒ€ê¹ƒ ë³€ìˆ˜ '{target_col}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
else:
    st.info("ì‹œë®¬ë ˆì´ì…˜ì„ ì‹œì‘í•˜ë ¤ë©´ CSV íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.") 


# í˜ì´ì§€ í•˜ë‹¨ ì†Œê°œ

st.markdown("---")
st.markdown("**ë¬¸ì˜ ë° í”¼ë“œë°±:**")
st.error("ë¬¸ì œì  ë° ê°œì„ ìš”ì²­ì‚¬í•­ì´ ìˆë‹¤ë©´, ì •ë³´ê¸°íšíŒ€ ê³ ë™í˜„ ì£¼ì„(ë‚´ì„ : 189)ì—ê²Œ í”¼ë“œë°± ë¶€íƒë“œë¦½ë‹ˆë‹¤. ì§€ì†ì ì¸ ê°œì„ ì— ë°˜ì˜í•˜ê² ìŠµë‹ˆë‹¤. ")