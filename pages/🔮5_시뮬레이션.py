import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
import xgboost as xgb
from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler
import shap
import plotly.express as px
import plotly.graph_objects as go
import io
import sys
import traceback

# í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams['font.family'] = 'Malgun Gothic'
plt.rcParams['axes.unicode_minus'] = False

# íŒŒì¼ ìƒë‹¨ì— ì¶”ê°€ (ê³µí†µ ê·¸ë˜í”„ ì„¤ì •)
def display_plot_centered(fig, width_pct=60):
    """ê·¸ë˜í”„ë¥¼ ì¤‘ì•™ì— í‘œì‹œí•˜ëŠ” í—¬í¼ í•¨ìˆ˜"""
    left_margin = (100 - width_pct) // 2
    right_margin = 100 - width_pct - left_margin
    cols = st.columns([left_margin, width_pct, right_margin])
    with cols[1]:
        st.pyplot(fig)

def display_plotly_centered(fig, width_pct=60):
    """Plotly ê·¸ë˜í”„ë¥¼ ì¤‘ì•™ì— í‘œì‹œí•˜ëŠ” í—¬í¼ í•¨ìˆ˜"""
    left_margin = (100 - width_pct) // 2
    right_margin = 100 - width_pct - left_margin
    cols = st.columns([left_margin, width_pct, right_margin])
    with cols[1]:
        st.plotly_chart(fig, use_container_width=True)

st.title("4. ì‹œë®¬ë ˆì´ì…˜")

# ì‹œë®¬ë ˆì´ì…˜ ê°œë… ì„¤ëª… ì¶”ê°€
with st.expander("ğŸ“š ì˜ˆì¸¡ ì‹œë®¬ë ˆì´ì…˜ì´ë€?"):
    st.markdown("""
    ### ì˜ˆì¸¡ ì‹œë®¬ë ˆì´ì…˜(Predictive Simulation)
    ì˜ˆì¸¡ ì‹œë®¬ë ˆì´ì…˜ì€ ê³¼ê±° ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•™ìŠµëœ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ë³€ìˆ˜ë“¤ì˜ ë‹¤ì–‘í•œ ê°’ ì¡°í•©ì— ë”°ë¥¸ ê²°ê³¼ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ê³¼ì •ì…ë‹ˆë‹¤.
    
    ### ì´ í˜ì´ì§€ì˜ ê¸°ëŠ¥
    
    **1. ë°ì´í„° ì¤€ë¹„**
    - CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì—¬ ë¶„ì„ ë°ì´í„°ë¥¼ ì¤€ë¹„í•©ë‹ˆë‹¤.
    - ì˜ˆì¸¡í•˜ê³ ì í•˜ëŠ” íƒ€ê²Ÿ ë³€ìˆ˜ë¥¼ ì„ íƒí•©ë‹ˆë‹¤.
    
    **2. ìƒê´€ê´€ê³„ ë¶„ì„**
    - íƒ€ê²Ÿ ë³€ìˆ˜ì™€ ìƒê´€ê´€ê³„ê°€ ë†’ì€ ì£¼ìš” ë³€ìˆ˜ë“¤ì„ ì‹ë³„í•©ë‹ˆë‹¤.
    - ì´ ë³€ìˆ˜ë“¤ì€ ì˜ˆì¸¡ ëª¨ë¸ì— ì¤‘ìš”í•œ ì¸ìê°€ ë©ë‹ˆë‹¤.
    
    **3. ëª¨ë¸ í›ˆë ¨**
    - ë¨¸ì‹ ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜(RandomForest ë˜ëŠ” XGBoost)ì„ ì‚¬ìš©í•˜ì—¬ ì˜ˆì¸¡ ëª¨ë¸ì„ í›ˆë ¨í•©ë‹ˆë‹¤.
    - í›ˆë ¨ëœ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê°€í•©ë‹ˆë‹¤(RÂ² ë° RMSE).
    - ë³€ìˆ˜ ì¤‘ìš”ë„ë¥¼ í™•ì¸í•˜ì—¬ ëª¨ë¸ì— ì˜í–¥ì„ ì£¼ëŠ” í•µì‹¬ ìš”ì¸ì„ íŒŒì•…í•©ë‹ˆë‹¤.
    
    **4. ì˜ˆì¸¡ ì‹œë®¬ë ˆì´ì…˜**
    - ì£¼ìš” ë³€ìˆ˜ë“¤ì˜ ê°’ì„ ì¡°ì •í•˜ë©´ì„œ ê²°ê³¼ ë³€í™”ë¥¼ ì¦‰ì‹œ í™•ì¸í•©ë‹ˆë‹¤.
    - ë‹¤ì–‘í•œ ì‹œë‚˜ë¦¬ì˜¤ì— ë”°ë¥¸ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ë¹„êµí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    - SHAP ê°’ì„ í†µí•´ ê° ë³€ìˆ˜ê°€ ì˜ˆì¸¡ ê²°ê³¼ì— ê¸°ì—¬í•˜ëŠ” ì •ë„ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.
    
    ### í™œìš© ë°©ë²•
    
    - **ê³µì • ìµœì í™”**: ì›í•˜ëŠ” ê²°ê³¼ë¥¼ ì–»ê¸° ìœ„í•œ ìµœì ì˜ ë³€ìˆ˜ ì¡°í•©ì„ ì°¾ìŠµë‹ˆë‹¤.
    - **ë¯¼ê°ë„ ë¶„ì„**: ì–´ë–¤ ë³€ìˆ˜ê°€ ê²°ê³¼ì— ê°€ì¥ í° ì˜í–¥ì„ ë¯¸ì¹˜ëŠ”ì§€ íŒŒì•…í•©ë‹ˆë‹¤.
    - **í’ˆì§ˆ ì˜ˆì¸¡**: íŠ¹ì • ì¡°ê±´ì—ì„œ ì œí’ˆ í’ˆì§ˆì´ ì–´ë–»ê²Œ ë³€í™”í• ì§€ ì˜ˆì¸¡í•©ë‹ˆë‹¤.
    - **ë¶ˆëŸ‰ë¥  ê°ì†Œ**: ë¶ˆëŸ‰ ë°œìƒ ê°€ëŠ¥ì„±ì´ ë†’ì€ ì¡°ê±´ì„ ì‚¬ì „ì— ì‹ë³„í•˜ì—¬ ì˜ˆë°©í•©ë‹ˆë‹¤.
    - **ë¹„ìš© ì ˆê°**: ì¬ë£Œ ë° ì—ë„ˆì§€ ì†Œë¹„ë¥¼ ìµœì í™”í•˜ì—¬ ë¹„ìš©ì„ ì ˆê°í•©ë‹ˆë‹¤.
    
    ### ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ ì„¤ëª…
    
    **RandomForest(ëœë¤ í¬ë ˆìŠ¤íŠ¸)**
    - ì—¬ëŸ¬ ì˜ì‚¬ê²°ì • íŠ¸ë¦¬ì˜ ì•™ìƒë¸” ëª¨ë¸ì…ë‹ˆë‹¤.
    - ë‹¤ì–‘í•œ ë°ì´í„° íƒ€ì…ì— ì ìš© ê°€ëŠ¥í•˜ê³  ê³¼ì í•©ì— ê°•í•©ë‹ˆë‹¤.
    - ë³€ìˆ˜ ê°„ ìƒí˜¸ì‘ìš©ì„ ì˜ í¬ì°©í•©ë‹ˆë‹¤.
    
    **XGBoost**
    - ê·¸ë˜ë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ… ê¸°ë°˜ì˜ ê³ ì„±ëŠ¥ ë¨¸ì‹ ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜ì…ë‹ˆë‹¤.
    - ì¼ë°˜ì ìœ¼ë¡œ ë” ë†’ì€ ì˜ˆì¸¡ ì •í™•ë„ë¥¼ ë³´ì´ì§€ë§Œ íŠœë‹ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    - ë³€ìˆ˜ ì¤‘ìš”ë„ ë° í•´ì„ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.
    """)

# íŒŒì¼ ì—…ë¡œë“œ ì˜ì—­
st.write("### ë°ì´í„° ì—…ë¡œë“œ")
uploaded_file = st.file_uploader("ì˜ˆì¸¡ ëª¨ë¸ë§ì„ ìœ„í•œ CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=['csv'])

# ë°ì´í„° ë¡œë“œ
data = None
if uploaded_file is not None:
    try:
        # íŒŒì¼ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸° (ë¬¸ì œ ì§„ë‹¨ìš©)
        file_bytes = uploaded_file.getvalue()
        try:
            preview_text = file_bytes[:1000].decode('utf-8')
        except UnicodeDecodeError:
            try:
                preview_text = file_bytes[:1000].decode('cp949')
            except UnicodeDecodeError:
                preview_text = "ì¸ì½”ë”© ë¬¸ì œë¡œ ë¯¸ë¦¬ë³´ê¸°ë¥¼ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        # êµ¬ë¶„ì ì„ íƒ ì˜µì…˜ ì¶”ê°€
        st.write("#### íŒŒì¼ ë¯¸ë¦¬ë³´ê¸°:")
        st.text(preview_text)
        
        delimiter_option = st.selectbox(
            "CSV êµ¬ë¶„ì ì„ íƒ:",
            options=[',', ';', '\t', '|'],
            index=0,
            format_func=lambda x: {',' : 'ì‰¼í‘œ(,)', ';' : 'ì„¸ë¯¸ì½œë¡ (;)', '\t': 'íƒ­(\\t)', '|': 'íŒŒì´í”„(|)'}[x]
        )
        
        # ë‹¤ì–‘í•œ ì¸ì½”ë”© ì‹œë„
        for encoding in ['utf-8', 'euc-kr', 'cp949']:
            try:
                # íŒŒì¼ í¬ì¸í„° ìœ„ì¹˜ ì´ˆê¸°í™”
                uploaded_file.seek(0)
                data = pd.read_csv(uploaded_file, encoding=encoding, delimiter=delimiter_option)
                if len(data.columns) <= 1 and data.columns[0].count(',') > 3:  # êµ¬ë¶„ì ê°ì§€ ë¬¸ì œì¸ ê²½ìš°
                    st.warning("êµ¬ë¶„ì ë¬¸ì œê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ êµ¬ë¶„ìë¥¼ ì„ íƒí•´ë³´ì„¸ìš”.")
                    data = None
                    continue
                break
            except Exception as e:
                continue
        
        if data is not None and len(data.columns) > 1:
            st.success(f"íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ! ë°ì´í„° í¬ê¸°: {data.shape[0]}í–‰ x {data.shape[1]}ì—´")
            
            # ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° í‘œì‹œ
            st.write("#### ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°:")
            st.dataframe(data.head())
        else:
            st.error("íŒŒì¼ì„ ì½ëŠ” ë° ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ êµ¬ë¶„ìë¥¼ ì„ íƒí•˜ê±°ë‚˜ íŒŒì¼ í˜•ì‹ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
            st.stop()
    except Exception as e:
        st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
        st.stop()

if data is not None:
    # íƒ€ê¹ƒ ë³€ìˆ˜ ì„ íƒ
    st.write("### ì˜ˆì¸¡ íƒ€ê¹ƒ ë³€ìˆ˜ ì„ íƒ")
    
    # ìˆ˜ì¹˜í˜• ë³€ìˆ˜ë§Œ ì¶”ì¶œ
    numeric_cols = data.select_dtypes(include=[np.number]).columns.tolist()
    
    if not numeric_cols:
        st.warning("ìˆ˜ì¹˜í˜• ë°ì´í„° ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. ë°ì´í„° íƒ€ì…ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        # ëª¨ë“  ì»¬ëŸ¼ì„ ë¬¸ìì—´ì—ì„œ ìˆ«ìë¡œ ë³€í™˜ ì‹œë„
        for col in data.columns:
            try:
                data[col] = pd.to_numeric(data[col])
                numeric_cols.append(col)
            except:
                pass
        
        if not numeric_cols:
            st.error("ë³€í™˜ ê°€ëŠ¥í•œ ìˆ˜ì¹˜í˜• ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
            st.stop()
    
    # ì¶”ì²œ íƒ€ê²Ÿ ìë™ ì„ íƒ
    default_target = None
    for col in numeric_cols:
        if 'ìš©ì¶œ' in col and ('ìµœì†Œ' in col or 'min' in col.lower() or 'Min' in col):
            default_target = col
            break
    
    # íƒ€ê²Ÿ ë³€ìˆ˜ ì„ íƒ UI
    if default_target:
        st.info(f"'{default_target}' ì»¬ëŸ¼ì´ ê¸°ë³¸ íƒ€ê²Ÿìœ¼ë¡œ ìë™ ì„ íƒë˜ì—ˆìŠµë‹ˆë‹¤. í•„ìš”í•˜ë©´ ë³€ê²½í•˜ì„¸ìš”.")
    
    target_col = st.selectbox(
        "ì˜ˆì¸¡í•  íƒ€ê¹ƒ ë³€ìˆ˜ë¥¼ ì„ íƒí•˜ì„¸ìš”:",
        numeric_cols,
        index=numeric_cols.index(default_target) if default_target and default_target in numeric_cols else 0
    )
    
    st.subheader(f"'{target_col}' ì˜ˆì¸¡ ëª¨ë¸ë§")
    
    # ë°ì´í„° ì „ì²˜ë¦¬
    numeric_data = data.select_dtypes(include=[np.number])
    
    # ìƒê´€ê´€ê³„ ë¶„ì„
    if target_col in numeric_data.columns:
        # NaN ê°’ ì²˜ë¦¬
        correlation_data = numeric_data.copy()
        correlation_data = correlation_data.fillna(correlation_data.mean())
        
        # ìƒê´€ê³„ìˆ˜ ê³„ì‚° - ì ˆëŒ€ê°’ì„ ì‚¬ìš©í•˜ì§€ ì•Šê³  ì›ë˜ ê°’ì„ ìœ ì§€
        correlations = correlation_data.corr()[target_col].sort_values(ascending=False)
        correlations = correlations.drop(target_col)  # íƒ€ê¹ƒ ë³€ìˆ˜ ìì‹ ê³¼ì˜ ìƒê´€ê´€ê³„ ì œì™¸
        
        # ìƒìœ„ ë³€ìˆ˜ ì„ íƒ ì‹œ ì ˆëŒ€ê°’ìœ¼ë¡œ ì •ë ¬í•˜ë˜, í‘œì‹œí•  ë•ŒëŠ” ì›ë˜ ê°’ ì‚¬ìš©
        top_indices = correlations.abs().sort_values(ascending=False).head(10).index
        correlation_with_target = correlations[top_indices]
        
        # ìƒê´€ê´€ê³„ ì‹œê°í™” (Plotlyë¡œ ë³€ê²½)
        fig_corr = go.Figure()
        
        # ìƒê´€ê³„ìˆ˜ì— ë”°ë¼ ìƒ‰ìƒ ì„¤ì •
        colors = ['#3498db' if val > 0 else '#e74c3c' for val in correlation_with_target.values]
        
        # ê°€ë¡œ ë§‰ëŒ€ ì°¨íŠ¸ ì¶”ê°€
        fig_corr.add_trace(
            go.Bar(
                y=correlation_with_target.index,
                x=correlation_with_target.values,  # ì›ë˜ ê°’ ì‚¬ìš© (ìŒìˆ˜/ì–‘ìˆ˜ ìœ ì§€)
                orientation='h',
                marker_color=colors,
                text=[f'{val:.2f}' for val in correlation_with_target.values],
                textposition='outside',
                hovertemplate='%{y}: %{x:.3f}<extra></extra>'
            )
        )
        
        # ë ˆì´ì•„ì›ƒ ì„¤ì •
        fig_corr.update_layout(
            title=f'{target_col}ì™€(ê³¼)ì˜ ìƒê´€ê´€ê³„ (ìƒìœ„ 10ê°œ)',
            xaxis_title='ìƒê´€ê³„ìˆ˜',
            yaxis_title='ë³€ìˆ˜',
            height=500,
            margin=dict(l=20, r=20, t=40, b=20),
            xaxis=dict(
                range=[-1, 1],  # xì¶• ë²”ìœ„ë¥¼ -1ì—ì„œ 1ë¡œ ê³ ì •
                zeroline=True,  # 0 ê¸°ì¤€ì„  ì¶”ê°€
                zerolinecolor='black',
                zerolinewidth=1
            )
        )
        
        # ì¤‘ì•™ì— í‘œì‹œ
        display_plotly_centered(fig_corr)
        
        # íƒ­ ìƒì„±
        tab1, tab2 = st.tabs(["ëª¨ë¸ í›ˆë ¨", "ì‹œë®¬ë ˆì´ì…˜"])
        
        with tab1:
            st.write("### ëª¨ë¸ í›ˆë ¨")
            
            # ëª¨ë¸ ì„ íƒ
            model_type = st.radio(
                "ëª¨ë¸ ì„ íƒ:",
                ["RandomForest", "XGBoost"],
                horizontal=True
            )
            
            # ë°ì´í„° ì „ì²˜ë¦¬ ì˜µì…˜
            st.write("### ë°ì´í„° ì „ì²˜ë¦¬ ì˜µì…˜")
            
            # ì´ìƒì¹˜ ì²˜ë¦¬ ì˜µì…˜
            outlier_options = st.expander("ì´ìƒì¹˜ ì²˜ë¦¬ ì˜µì…˜", expanded=True)
            with outlier_options:
                remove_outliers = st.checkbox("ì´ìƒì¹˜ ì œê±°", value=True, 
                                            help="í•™ìŠµ ë°ì´í„°ì—ì„œ ì´ìƒì¹˜ë¥¼ ì œê±°í•˜ì—¬ ëª¨ë¸ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.")
                
                outlier_method = st.radio(
                    "ì´ìƒì¹˜ íƒì§€ ë°©ë²•:",
                    ["Z-ì ìˆ˜", "IQR ë°©ë²•"],
                    horizontal=True,
                    help="Z-ì ìˆ˜: í‰ê· ì—ì„œ n í‘œì¤€í¸ì°¨ ì´ìƒ ë–¨ì–´ì§„ ê°’ì„ ì´ìƒì¹˜ë¡œ ê°„ì£¼\nIQR: ì‚¬ë¶„ìœ„ìˆ˜ ë²”ìœ„ë¥¼ ë²—ì–´ë‚œ ê°’ì„ ì´ìƒì¹˜ë¡œ ê°„ì£¼"
                )
                
                if outlier_method == "Z-ì ìˆ˜":
                    z_threshold = st.slider("Z-ì ìˆ˜ ì„ê³„ê°’", 
                                          min_value=2.0, max_value=5.0, value=3.0, step=0.1,
                                          help="ì´ ê°’ë³´ë‹¤ í° Z-ì ìˆ˜ë¥¼ ê°€ì§„ ë°ì´í„°ë¥¼ ì´ìƒì¹˜ë¡œ ê°„ì£¼í•©ë‹ˆë‹¤.")
                else:  # IQR ë°©ë²•
                    iqr_multiplier = st.slider("IQR ê³±ìˆ˜", 
                                             min_value=1.0, max_value=3.0, value=1.5, step=0.1,
                                             help="IQR Ã— ì´ ê°’ì„ ì´ˆê³¼í•˜ëŠ” ë°ì´í„°ë¥¼ ì´ìƒì¹˜ë¡œ ê°„ì£¼í•©ë‹ˆë‹¤.")
            
            # ë°ì´í„° ìŠ¤ì¼€ì¼ë§ ì˜µì…˜
            scaling_options = st.expander("ë°ì´í„° ìŠ¤ì¼€ì¼ë§ ì˜µì…˜", expanded=True)
            with scaling_options:
                apply_scaling = st.checkbox("ë°ì´í„° ìŠ¤ì¼€ì¼ë§ ì ìš©", value=True,
                                          help="ë³€ìˆ˜ë¥¼ ë™ì¼í•œ ìŠ¤ì¼€ì¼ë¡œ ì¡°ì •í•˜ì—¬ ëª¨ë¸ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.")
                
                if apply_scaling:
                    scaler_method = st.radio(
                        "ìŠ¤ì¼€ì¼ë§ ë°©ë²•:",
                        ["í‘œì¤€í™”(StandardScaler)", "ë¡œë²„ìŠ¤íŠ¸ ìŠ¤ì¼€ì¼ë§(RobustScaler)", "ì •ê·œí™”(MinMaxScaler)"],
                        horizontal=True,
                        help="í‘œì¤€í™”: í‰ê·  0, í‘œì¤€í¸ì°¨ 1ë¡œ ë³€í™˜\në¡œë²„ìŠ¤íŠ¸: ì¤‘ì•™ê°’ê³¼ IQRì„ ì‚¬ìš©í•˜ì—¬ ì´ìƒì¹˜ì— ê°•ê±´í•œ ìŠ¤ì¼€ì¼ë§\nì •ê·œí™”: ìµœì†Œ-ìµœëŒ€ ìŠ¤ì¼€ì¼ë§ìœ¼ë¡œ 0~1 ë²”ìœ„ë¡œ ë³€í™˜"
                    )
            
            # í›ˆë ¨ ë²„íŠ¼
            if st.button("ëª¨ë¸ í›ˆë ¨"):
                with st.spinner("ëª¨ë¸ í›ˆë ¨ ì¤‘..."):
                    # ì›ë³¸ ë°ì´í„° ë³´ì¡´
                    X_orig = correlation_data[top_indices].copy()
                    y_orig = correlation_data[target_col].copy()
                    
                    # ì´ìƒì¹˜ í™•ì¸ ë° ì‹œê°í™”
                    if remove_outliers:
                        if outlier_method == "Z-ì ìˆ˜":
                            # ì´ìƒì¹˜ ì œê±° ì „ ë°ì´í„° ê±´ìˆ˜
                            before_count = len(X_orig)
                            
                            # Z-ì ìˆ˜ ê³„ì‚° ë° ì´ìƒì¹˜ ì‹ë³„
                            z_scores = np.abs((X_orig - X_orig.mean()) / X_orig.std())
                            outlier_mask = (z_scores > z_threshold).any(axis=1)
                            
                            # íƒ€ê²Ÿ ë³€ìˆ˜ì˜ Z-ì ìˆ˜ë„ ê³„ì‚°
                            y_z_score = np.abs((y_orig - y_orig.mean()) / y_orig.std())
                            y_outlier_mask = (y_z_score > z_threshold)
                            
                            # ì´ìƒì¹˜ê°€ ìˆëŠ” í–‰ì„ ì‹ë³„
                            combined_mask = outlier_mask | y_outlier_mask
                            
                            # ì´ìƒì¹˜ ì œê±°ëœ ë°ì´í„°
                            X_cleaned = X_orig[~combined_mask]
                            y_cleaned = y_orig[~combined_mask]
                            
                            # ì œê±°ëœ ë°ì´í„° ìˆ˜ ê³„ì‚°
                            removed_count = before_count - len(X_cleaned)
                            removal_percentage = (removed_count / before_count) * 100
                            
                            st.info(f"Z-ì ìˆ˜ {z_threshold} ì´ìƒì¸ ì´ìƒì¹˜ {removed_count}ê°œ({removal_percentage:.1f}%)ë¥¼ ì œê±°í–ˆìŠµë‹ˆë‹¤. (ì›ë³¸: {before_count}ê°œ â†’ ì •ì œ: {len(X_cleaned)}ê°œ)")
                            
                        else:  # IQR ë°©ë²•
                            # ì´ìƒì¹˜ ì œê±° ì „ ë°ì´í„° ê±´ìˆ˜
                            before_count = len(X_orig)
                            
                            # ê° íŠ¹ì„±ì— ëŒ€í•´ IQR ê¸°ë°˜ ì´ìƒì¹˜ íƒì§€
                            outlier_rows = []
                            for col in X_orig.columns:
                                Q1 = X_orig[col].quantile(0.25)
                                Q3 = X_orig[col].quantile(0.75)
                                IQR = Q3 - Q1
                                lower_bound = Q1 - iqr_multiplier * IQR
                                upper_bound = Q3 + iqr_multiplier * IQR
                                
                                # ì´ìƒì¹˜ê°€ ìˆëŠ” í–‰ ì¸ë±ìŠ¤
                                feature_outliers = X_orig[(X_orig[col] < lower_bound) | (X_orig[col] > upper_bound)].index
                                outlier_rows.extend(feature_outliers)
                            
                            # íƒ€ê²Ÿ ë³€ìˆ˜ì˜ ì´ìƒì¹˜ë„ í™•ì¸
                            Q1 = y_orig.quantile(0.25)
                            Q3 = y_orig.quantile(0.75)
                            IQR = Q3 - Q1
                            lower_bound = Q1 - iqr_multiplier * IQR
                            upper_bound = Q3 + iqr_multiplier * IQR
                            
                            target_outliers = y_orig[(y_orig < lower_bound) | (y_orig > upper_bound)].index
                            outlier_rows.extend(target_outliers)
                            
                            # ì¤‘ë³µ ì œê±°í•˜ì—¬ ì´ìƒì¹˜ê°€ ìˆëŠ” ëª¨ë“  í–‰ ì¸ë±ìŠ¤
                            outlier_indices = list(set(outlier_rows))
                            
                            # ì´ìƒì¹˜ ì œê±°
                            X_cleaned = X_orig.drop(outlier_indices)
                            y_cleaned = y_orig.drop(outlier_indices)
                            
                            # ì œê±°ëœ ë°ì´í„° ìˆ˜ ê³„ì‚°
                            removed_count = before_count - len(X_cleaned)
                            removal_percentage = (removed_count / before_count) * 100
                            
                            st.info(f"IQR Ã— {iqr_multiplier} ë²”ìœ„ë¥¼ ë²—ì–´ë‚œ ì´ìƒì¹˜ {removed_count}ê°œ({removal_percentage:.1f}%)ë¥¼ ì œê±°í–ˆìŠµë‹ˆë‹¤. (ì›ë³¸: {before_count}ê°œ â†’ ì •ì œ: {len(X_cleaned)}ê°œ)")
                    else:
                        # ì´ìƒì¹˜ ì œê±° ì—†ì´ ì›ë³¸ ë°ì´í„° ì‚¬ìš©
                        X_cleaned = X_orig.copy()
                        y_cleaned = y_orig.copy()
                    
                    # ë°ì´í„° ë¶€ì¡± ì‹œ ê²½ê³ 
                    if len(X_cleaned) < 20:
                        st.warning("ë°ì´í„°ê°€ ë„ˆë¬´ ì ìŠµë‹ˆë‹¤(20ê°œ ë¯¸ë§Œ). ëª¨ë¸ ì„±ëŠ¥ì´ ì¢‹ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                        if remove_outliers:
                            st.warning("ì´ìƒì¹˜ ì œê±° ê¸°ì¤€ì„ ì™„í™”í•˜ê±°ë‚˜ ë¹„í™œì„±í™”í•˜ëŠ” ê²ƒì„ ê³ ë ¤í•˜ì„¸ìš”.")
                    
                    # ìŠ¤ì¼€ì¼ë§ ì ìš©
                    if apply_scaling:
                        if scaler_method == "í‘œì¤€í™”(StandardScaler)":
                            scaler = StandardScaler()
                            st.session_state.scaler = scaler
                            st.session_state.scaling_method = "standard"
                        elif scaler_method == "ë¡œë²„ìŠ¤íŠ¸ ìŠ¤ì¼€ì¼ë§(RobustScaler)":
                            scaler = RobustScaler()
                            st.session_state.scaler = scaler
                            st.session_state.scaling_method = "robust"
                        else:  # ì •ê·œí™”(MinMaxScaler)
                            scaler = MinMaxScaler()
                            st.session_state.scaler = scaler
                            st.session_state.scaling_method = "minmax"
                        
                        # X ë°ì´í„° ìŠ¤ì¼€ì¼ë§
                        X_scaled = pd.DataFrame(
                            scaler.fit_transform(X_cleaned),
                            columns=X_cleaned.columns,
                            index=X_cleaned.index
                        )
                        
                        st.info(f"{scaler_method}ë¥¼ ì ìš©í–ˆìŠµë‹ˆë‹¤.")
                    else:
                        X_scaled = X_cleaned
                        st.session_state.scaling_method = None
                    
                    # í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë¶„í• 
                    X_train, X_test, y_train, y_test = train_test_split(
                        X_scaled, y_cleaned, test_size=0.2, random_state=42
                    )
                    
                    # ëª¨ë¸ í›ˆë ¨
                    if model_type == "RandomForest":
                        model = RandomForestRegressor(n_estimators=100, random_state=42)
                    else:  # XGBoost
                        model = xgb.XGBRegressor(n_estimators=100, random_state=42)
                    
                    model.fit(X_train, y_train)
                    
                    # ëª¨ë¸ í‰ê°€
                    y_pred = model.predict(X_test)
                    mse = mean_squared_error(y_test, y_pred)
                    rmse = np.sqrt(mse)
                    r2 = r2_score(y_test, y_pred)
                    
                    # ê²°ê³¼ ì¶œë ¥
                    st.write(f"**í‰ê·  ì œê³± ì˜¤ì°¨(MSE):** {mse:.4f}")
                    st.write(f"**í‰ê·  ì œê³±ê·¼ ì˜¤ì°¨(RMSE):** {rmse:.4f}")
                    st.write(f"**RÂ² ì ìˆ˜:** {r2:.4f}")
                    
                    # ëª¨ë¸ ë° íŠ¹ì„± ì €ì¥
                    st.session_state.model = model
                    st.session_state.model_features = top_indices.tolist()
                    st.session_state.remove_outliers = remove_outliers
                    st.session_state.apply_scaling = apply_scaling
                    
                    if remove_outliers:
                        if outlier_method == "Z-ì ìˆ˜":
                            st.session_state.outlier_method = "zscore"
                            st.session_state.outlier_param = z_threshold
                        else:
                            st.session_state.outlier_method = "iqr"
                            st.session_state.outlier_param = iqr_multiplier
                    
                    # ì‹¤ì œê°’-ì˜ˆì¸¡ê°’ ë¹„êµ ê·¸ë˜í”„ (Plotlyë¡œ ë³€ê²½)
                    fig_compare = go.Figure()

                    # ì‚°ì ë„ ì¶”ê°€
                    fig_compare.add_trace(
                        go.Scatter(
                            x=y_test,
                            y=y_pred,
                            mode='markers',
                            marker=dict(
                                size=8,
                                color='rgba(0, 123, 255, 0.7)',
                                line=dict(
                                    color='rgba(0, 123, 255, 1.0)',
                                    width=1
                                )
                            ),
                            name='ì˜ˆì¸¡ê°’',
                            hovertemplate='ì‹¤ì œê°’: %{x:.4f}<br>ì˜ˆì¸¡ê°’: %{y:.4f}<extra></extra>'
                        )
                    )

                    # ì´ìƒì ì¸ ì˜ˆì¸¡ì„  (ëŒ€ê°ì„ ) ì¶”ê°€
                    min_val = min(min(y_test), min(y_pred))
                    max_val = max(max(y_test), max(y_pred))
                    fig_compare.add_trace(
                        go.Scatter(
                            x=[min_val, max_val],
                            y=[min_val, max_val],
                            mode='lines',
                            line=dict(color='red', dash='dash'),
                            name='ì´ìƒì ì¸ ì˜ˆì¸¡'
                        )
                    )

                    # ë ˆì´ì•„ì›ƒ ì„¤ì •
                    fig_compare.update_layout(
                        title='ì‹¤ì œê°’ vs ì˜ˆì¸¡ê°’',
                        xaxis_title='ì‹¤ì œê°’',
                        yaxis_title='ì˜ˆì¸¡ê°’',
                        height=500,
                        width=700,
                        showlegend=True,
                        hovermode='closest'
                    )

                    # ì¶• ë²”ìœ„ë¥¼ ë™ì¼í•˜ê²Œ ì„¤ì •
                    overall_min = min(min_val, min_val)
                    overall_max = max(max_val, max_val)
                    padding = (overall_max - overall_min) * 0.05
                    fig_compare.update_xaxes(range=[overall_min - padding, overall_max + padding])
                    fig_compare.update_yaxes(range=[overall_min - padding, overall_max + padding])

                    # ê·¸ë¦¬ë“œ ì¶”ê°€
                    fig_compare.update_layout(
                        xaxis=dict(
                            showgrid=True,
                            gridwidth=1,
                            gridcolor='LightGrey'
                        ),
                        yaxis=dict(
                            showgrid=True,
                            gridwidth=1,
                            gridcolor='LightGrey'
                        )
                    )

                    # ê·¸ë˜í”„ í‘œì‹œ
                    display_plotly_centered(fig_compare)
                    
                    # ë³€ìˆ˜ ì¤‘ìš”ë„ ì‹œê°í™”
                    if model_type == "RandomForest":
                        # ëœë¤ í¬ë ˆìŠ¤íŠ¸ ë³€ìˆ˜ ì¤‘ìš”ë„
                        feature_importance = model.feature_importances_
                    elif model_type == "XGBoost":
                        # XGBoost ë³€ìˆ˜ ì¤‘ìš”ë„
                        feature_importance = model.feature_importances_
                    
                    # ë³€ìˆ˜ ì¤‘ìš”ë„ë¥¼ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜
                    feature_importance_df = pd.DataFrame({
                        'Feature': X_train.columns,
                        'Importance': feature_importance
                    })

                    # ì¤‘ìš”ë„ ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
                    feature_importance_df = feature_importance_df.sort_values('Importance', ascending=False)

                    # Plotly ê·¸ë˜í”„ ìƒì„±
                    fig_importance = go.Figure()

                    # ë°” ì°¨íŠ¸ ì¶”ê°€ (ë‚¨ìƒ‰ìœ¼ë¡œ ë³€ê²½)
                    fig_importance.add_trace(
                        go.Bar(
                            y=feature_importance_df['Feature'],
                            x=feature_importance_df['Importance'],
                            orientation='h',
                            marker_color='#3498db',  # ë‚¨ìƒ‰ìœ¼ë¡œ ë³€ê²½
                            text=[f'{val:.4f}' for val in feature_importance_df['Importance']],
                            textposition='outside',
                            hovertemplate='%{y}: %{x:.4f}<extra></extra>'
                        )
                    )

                    # ë ˆì´ì•„ì›ƒ ì„¤ì •
                    fig_importance.update_layout(
                        title='ëª¨ë¸ì˜ ì „ë°˜ì ì¸ ë³€ìˆ˜ ì¤‘ìš”ë„',
                        xaxis_title='ì¤‘ìš”ë„',
                        yaxis_title='ë³€ìˆ˜',
                        height=500,
                        margin=dict(l=20, r=20, t=40, b=20),
                        xaxis=dict(
                            range=[0, max(feature_importance_df['Importance']) * 1.1],  # 0ë¶€í„° ì‹œì‘í•˜ë„ë¡ ìˆ˜ì •
                            showgrid=True,
                            gridwidth=1,
                            gridcolor='LightGrey'
                        ),
                        yaxis=dict(
                            autorange='reversed'  # ì¤‘ìš”ë„ê°€ ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬
                        )
                    )

                    # ê·¸ë˜í”„ í‘œì‹œ
                    st.subheader("ëª¨ë¸ì˜ ì „ë°˜ì ì¸ ë³€ìˆ˜ ì¤‘ìš”ë„")
                    display_plotly_centered(fig_importance)
                    
                    st.success("ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ! ì´ì œ 'ì‹œë®¬ë ˆì´ì…˜' íƒ­ìœ¼ë¡œ ì´ë™í•˜ì—¬ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        
        with tab2:
            st.write("### ì‹œë®¬ë ˆì´ì…˜")
            
            if 'model' in st.session_state and 'model_features' in st.session_state:
                st.write("ì•„ë˜ ë³€ìˆ˜ë“¤ì˜ ê°’ì„ ì¡°ì •í•˜ì—¬ ì˜ˆì¸¡í•´ë³´ì„¸ìš”:")
                
                # ì…ë ¥ ìœ„ì ¯ ìƒì„±
                input_values = {}
                for feature in st.session_state.model_features:
                    min_val = float(numeric_data[feature].min())
                    max_val = float(numeric_data[feature].max())
                    mean_val = float(numeric_data[feature].mean())
                    std_val = float(numeric_data[feature].std())
                    
                    # ìŠ¬ë¼ì´ë” ìƒì„±
                    input_values[feature] = st.slider(
                        f"{feature} (í‰ê· : {mean_val:.2f}, í‘œì¤€í¸ì°¨: {std_val:.2f})",
                        min_val,
                        max_val,
                        mean_val,
                        step=(max_val-min_val)/100
                    )
                
                # ì˜ˆì¸¡ ìˆ˜í–‰ ë²„íŠ¼
                if st.button("ì˜ˆì¸¡ ìˆ˜í–‰"):
                    with st.spinner("ì˜ˆì¸¡ ì¤‘..."):
                        # ì…ë ¥ê°’ìœ¼ë¡œ ë°ì´í„°í”„ë ˆì„ ìƒì„±
                        input_df = pd.DataFrame([input_values])
                        
                        # ìŠ¤ì¼€ì¼ë§ ì ìš© (í•„ìš”í•œ ê²½ìš°)
                        if 'apply_scaling' in st.session_state and st.session_state.apply_scaling:
                            input_scaled = st.session_state.scaler.transform(input_df)
                            input_scaled_df = pd.DataFrame(input_scaled, columns=input_df.columns)
                            prediction = st.session_state.model.predict(input_scaled_df)[0]
                        else:
                            prediction = st.session_state.model.predict(input_df)[0]
                        
                        # ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì„¸ì…˜ ìƒíƒœì— ì €ì¥ (ì§€ì†ì„± ìœ ì§€)
                        st.session_state.last_prediction = prediction
                        st.session_state.last_input_values = input_values.copy()
                        
                        # íƒ€ê²Ÿ í†µê³„ ì •ë³´ ì €ì¥
                        st.session_state.target_mean = numeric_data[target_col].mean()
                        st.session_state.target_min = numeric_data[target_col].min()
                        st.session_state.target_max = numeric_data[target_col].max()
                
                # ì˜ˆì¸¡ ê²°ê³¼ê°€ ìˆìœ¼ë©´ í•­ìƒ í‘œì‹œ (ë³€ìˆ˜ë³„ ê¸°ì—¬ë„ ë¶„ì„ê³¼ ë¬´ê´€í•˜ê²Œ ìœ ì§€)
                if 'last_prediction' in st.session_state:
                    prediction = st.session_state.last_prediction
                    target_mean = st.session_state.target_mean
                    target_min = st.session_state.target_min
                    target_max = st.session_state.target_max
                    
                    # ì˜ˆì¸¡ ê²°ê³¼ í‘œì‹œ
                    st.success(f"### ì˜ˆì¸¡ëœ {target_col}: {prediction:.4f}")
                    
                    # ì¶”ê°€ ì •ë³´: í‰ê·  ë° ë²”ìœ„ì™€ ë¹„êµ
                    col1, col2, col3 = st.columns(3)
                    col1.metric("í‰ê·  ëŒ€ë¹„", f"{(prediction - target_mean):.4f}", 
                                f"{((prediction - target_mean) / target_mean * 100):.2f}%")
                    col2.metric("ìµœì†Œê°’", f"{target_min:.4f}")
                    col3.metric("ìµœëŒ€ê°’", f"{target_max:.4f}")
                
                # ë³€ìˆ˜ë³„ ê¸°ì—¬ë„ ë¶„ì„ (SHAP ëŒ€ì‹  ëŒ€ì²´ ë°©ë²• ì‚¬ìš©)
                if st.checkbox("ë³€ìˆ˜ë³„ ê¸°ì—¬ë„ ë¶„ì„ ë³´ê¸°", key="feature_impact_checkbox"):
                    with st.spinner("ë³€ìˆ˜ ê¸°ì—¬ë„ ë¶„ì„ ì¤‘..."):
                        try:
                            # ëª¨ë¸ í™•ì¸
                            if 'model' not in st.session_state:
                                st.error("í›ˆë ¨ëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € 'ëª¨ë¸ í›ˆë ¨' íƒ­ì—ì„œ ëª¨ë¸ì„ í›ˆë ¨í•´ì£¼ì„¸ìš”.")
                            else:
                                # 1. ëª¨ë¸ ê¸°ë³¸ íŠ¹ì„± ì¤‘ìš”ë„ í‘œì‹œ (ê°€ëŠ¥í•œ ê²½ìš°)
                                if hasattr(st.session_state.model, 'feature_importances_'):
                                    st.subheader("ëª¨ë¸ì˜ ì „ë°˜ì ì¸ ë³€ìˆ˜ ì¤‘ìš”ë„")
                                    
                                    importances = st.session_state.model.feature_importances_
                                    # ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬í•˜ì—¬ ìƒìœ„ 10ê°œ ì„ íƒ
                                    indices = np.argsort(importances)[::-1][:10]  # ìƒìœ„ 10ê°œ
                                    
                                    feature_importance_df = pd.DataFrame({
                                        'ë³€ìˆ˜': [st.session_state.model_features[i] for i in indices],
                                        'ì¤‘ìš”ë„': [importances[i] for i in indices]
                                    })
                                    
                                    # ì´ë¯¸ì§€ì²˜ëŸ¼ ìˆ˜í‰ ë§‰ëŒ€ ê·¸ë˜í”„ í‘œì‹œ (Plotly ì‚¬ìš©)
                                    fig_impact = go.Figure()

                                    # ëª¨ë“  ë§‰ëŒ€ë¥¼ ë‚¨ìƒ‰ìœ¼ë¡œ ì„¤ì •
                                    fig_impact.add_trace(
                                        go.Bar(
                                            y=feature_importance_df['ë³€ìˆ˜'],
                                            x=feature_importance_df['ì¤‘ìš”ë„'],
                                            orientation='h',
                                            marker_color='#3498db',  # ëª¨ë‘ ë‚¨ìƒ‰ìœ¼ë¡œ í†µì¼
                                            text=[f'{val:.4f}' for val in feature_importance_df['ì¤‘ìš”ë„']],
                                            textposition='outside',
                                            hovertemplate='%{y}: %{x:.4f}<extra></extra>'
                                        )
                                    )

                                    # ë ˆì´ì•„ì›ƒ ì„¤ì •
                                    max_impact = max(importances) if len(importances) > 0 else 0
                                    fig_impact.update_layout(
                                        title=f"ëª¨ë¸ì˜ ì „ë°˜ì ì¸ ë³€ìˆ˜ ì¤‘ìš”ë„",
                                        xaxis_title="ì¤‘ìš”ë„",
                                        yaxis=dict(
                                            title="ë³€ìˆ˜",
                                            autorange="reversed"  # ìœ„ì—ì„œë¶€í„° ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
                                        ),
                                        height=500,
                                        margin=dict(l=20, r=20, t=40, b=20),
                                        xaxis=dict(
                                            range=[0, max_impact*1.1],  # 0ë¶€í„° ì‹œì‘í•˜ë„ë¡ ìˆ˜ì •
                                            showgrid=True,
                                            gridwidth=1,
                                            gridcolor='LightGrey'
                                        )
                                    )

                                    # ì¤‘ì•™ì— í‘œì‹œ
                                    display_plotly_centered(fig_impact)
                                
                                # ë§ˆì§€ë§‰ ì˜ˆì¸¡ì´ ìˆëŠ” ê²½ìš°ì—ë§Œ ë³€ìˆ˜ë³„ ì˜í–¥ë„ ë¶„ì„
                                if 'last_prediction' in st.session_state and 'last_input_values' in st.session_state:
                                    # í˜„ì¬ ì˜ˆì¸¡ì— ëŒ€í•œ ë³€ìˆ˜ë³„ ì˜í–¥ë„ ë¶„ì„
                                    st.subheader(f"{target_col} ì˜ˆì¸¡ì— ëŒ€í•œ ë³€ìˆ˜ë³„ ì˜í–¥")
                                    
                                    # ì €ì¥ëœ ì…ë ¥ê°’ ì‚¬ìš©
                                    input_values = st.session_state.last_input_values
                                    input_df = pd.DataFrame([input_values])
                                    base_prediction = st.session_state.last_prediction
                                    
                                    # ê° ë³€ìˆ˜ì˜ ì˜í–¥ë„ë¥¼ ê°œë³„ì ìœ¼ë¡œ í…ŒìŠ¤íŠ¸
                                    impact_results = []
                                    
                                    # ê° íŠ¹ì„±ì— ëŒ€í•´ ë°˜ë³µ
                                    for feature in st.session_state.model_features:
                                        # ê° íŠ¹ì„±ì˜ ì¤‘ìš”ë„ë¥¼ ì¸¡ì •í•˜ê¸° ìœ„í•´ ê°œë³„ í…ŒìŠ¤íŠ¸
                                        feature_min = numeric_data[feature].min()
                                        feature_max = numeric_data[feature].max()
                                        feature_mean = numeric_data[feature].mean()
                                        feature_range = feature_max - feature_min
                                        
                                        # í˜„ì¬ íŠ¹ì„±ì˜ ê°’
                                        current_value = input_values[feature]
                                        
                                        # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ìƒì„± (ìµœì†Œ, í‰ê· , ìµœëŒ€ê°’)
                                        test_values = {
                                            'ìµœì†Œê°’': feature_min,
                                            'í‰ê· ê°’': feature_mean,
                                            'ìµœëŒ€ê°’': feature_max
                                        }
                                        
                                        # ë‹¤ì–‘í•œ ê°’ìœ¼ë¡œ í…ŒìŠ¤íŠ¸
                                        predictions = {}
                                        for label, value in test_values.items():
                                            # ì´ë¯¸ í˜„ì¬ ê°’ê³¼ ê°™ìœ¼ë©´ ê±´ë„ˆë›°ê¸°
                                            if value == current_value:
                                                predictions[label] = base_prediction
                                                continue
                                                
                                            # íŠ¹ì„± ê°’ ë³€ê²½
                                            modified_input = input_df.copy()
                                            modified_input[feature] = value
                                            
                                            # ë³€ê²½ëœ ì…ë ¥ìœ¼ë¡œ ì˜ˆì¸¡
                                            if 'apply_scaling' in st.session_state and st.session_state.apply_scaling:
                                                modified_input_scaled = st.session_state.scaler.transform(modified_input)
                                                modified_input_scaled_df = pd.DataFrame(modified_input_scaled, columns=modified_input.columns)
                                                modified_prediction = st.session_state.model.predict(modified_input_scaled_df)[0]
                                            else:
                                                modified_prediction = st.session_state.model.predict(modified_input)[0]
                                            
                                            predictions[label] = modified_prediction
                                        
                                        # ë³€ìˆ˜ì˜ ì˜í–¥ë„ ê³„ì‚° (ìµœëŒ€-ìµœì†Œ ì°¨ì´)
                                        if len(predictions) > 1:
                                            impact = predictions['ìµœëŒ€ê°’'] - predictions['ìµœì†Œê°’']
                                            # í˜„ì¬ ê°’ì´ í‰ê· ë³´ë‹¤ ë†’ì€ì§€ ë‚®ì€ì§€ì— ë”°ë¼ ë¶€í˜¸ ê²°ì •
                                            if current_value > feature_mean:
                                                direction = 1  # í‰ê· ë³´ë‹¤ ë†’ìŒ
                                            else:
                                                direction = -1  # í‰ê· ë³´ë‹¤ ë‚®ìŒ
                                                
                                            # ì „ì²´ ë²”ìœ„ ëŒ€ë¹„ í˜„ì¬ ê°’ì˜ ìƒëŒ€ì  ìœ„ì¹˜ì— ë”°ë¼ ì˜í–¥ë„ ê°€ì¤‘ì¹˜ ë¶€ì—¬
                                            relative_position = (current_value - feature_mean) / (feature_range/2) if feature_range > 0 else 0
                                            # ì˜í–¥ë„ëŠ” ë³€ìˆ˜ ë²”ìœ„ì—ì„œì˜ ë³€í™”ëŸ‰ * í˜„ì¬ ê°’ì˜ ìƒëŒ€ì  ìœ„ì¹˜ë¡œ ê³„ì‚°
                                            weighted_impact = impact * relative_position
                                        else:
                                            weighted_impact = 0  # ì˜í–¥ë„ ì¸¡ì • ë¶ˆê°€ëŠ¥í•œ ê²½ìš°
                                        
                                        # ê²°ê³¼ ì €ì¥
                                        impact_results.append({
                                            'ë³€ìˆ˜': feature,
                                            'í˜„ì¬ê°’': current_value,
                                            'ìµœì†Œì˜ˆì¸¡': predictions.get('ìµœì†Œê°’', base_prediction),
                                            'ìµœëŒ€ì˜ˆì¸¡': predictions.get('ìµœëŒ€ê°’', base_prediction),
                                            'ì˜í–¥ë„': weighted_impact
                                        })
                                    
                                    # ê²°ê³¼ë¥¼ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜
                                    impact_df = pd.DataFrame(impact_results)
                                    
                                    # ì˜í–¥ë„ì˜ ì ˆëŒ€ê°’ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
                                    impact_df = impact_df.sort_values(by='ì˜í–¥ë„', key=abs, ascending=False)
                                    
                                    # ìƒìœ„ 10ê°œ ë³€ìˆ˜ë§Œ í‘œì‹œ
                                    impact_df = impact_df.head(10)
                                    
                                    # ì¤‘ë³µë˜ëŠ” í‘œ ì œê±° (ìƒì„¸ ë°ì´í„° expanderë¡œ ì¶©ë¶„í•¨)
                                    
                                    # ì´ë¯¸ì§€ì²˜ëŸ¼ ìˆ˜í‰ ë§‰ëŒ€ ê·¸ë˜í”„ í‘œì‹œ (Plotly ì‚¬ìš©)
                                    fig_impact = go.Figure()

                                    # ì˜í–¥ë„ì— ë”°ë¼ ìƒ‰ìƒ ì„¤ì •
                                    colors = ['#3498db' if x > 0 else '#e74c3c' for x in impact_df['ì˜í–¥ë„'].values]

                                    # ìˆ˜í‰ ë§‰ëŒ€ ì¶”ê°€
                                    fig_impact.add_trace(
                                        go.Bar(
                                            y=impact_df['ë³€ìˆ˜'],
                                            x=impact_df['ì˜í–¥ë„'],
                                            orientation='h',
                                            marker_color=colors,
                                            text=[f'{val:.4f}' for val in impact_df['ì˜í–¥ë„']],
                                            textposition='outside',
                                            hovertemplate='%{y}: %{x:.4f}<extra></extra>'
                                        )
                                    )

                                    # ë ˆì´ì•„ì›ƒ ì„¤ì •
                                    max_impact = max(abs(np.max(impact_df['ì˜í–¥ë„'].values)), abs(np.min(impact_df['ì˜í–¥ë„'].values))) if len(impact_df['ì˜í–¥ë„'].values) > 0 else 0
                                    fig_impact.update_layout(
                                        title=f"{target_col} ì˜ˆì¸¡ì— ëŒ€í•œ ë³€ìˆ˜ë³„ ì˜í–¥ë„",
                                        xaxis_title="ì˜ˆì¸¡ê°’ì— ëŒ€í•œ ì˜í–¥ë„",
                                        yaxis=dict(
                                            title="ë³€ìˆ˜",
                                            autorange="reversed"  # ìœ„ì—ì„œë¶€í„° ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
                                        ),
                                        height=500,
                                        margin=dict(l=20, r=20, t=40, b=20),
                                        xaxis=dict(
                                            range=[-max_impact*1.1, max_impact*1.1] if max_impact > 0 else None,
                                            zeroline=True,
                                            zerolinecolor='gray',
                                            zerolinewidth=1,
                                            showgrid=True,
                                            gridwidth=1,
                                            gridcolor='LightGrey'
                                        )
                                    )

                                    # ì¤‘ì•™ì— í‘œì‹œ
                                    display_plotly_centered(fig_impact)
                                    
                                    # ìƒì„¸ ë°ì´í„° í‘œì‹œ
                                    with st.expander("ë³€ìˆ˜ë³„ ì˜í–¥ë„ ìƒì„¸ ë°ì´í„°"):
                                        st.dataframe(impact_df)
                                    
                                    # ê²°ê³¼ í•´ì„ ê°€ì´ë“œ
                                    with st.expander("ğŸ’¡ ë³€ìˆ˜ ì˜í–¥ë„ í•´ì„ ë°©ë²•"):
                                        st.markdown("""
                                        ### ë³€ìˆ˜ ì˜í–¥ë„ í•´ì„ ë°©ë²•
                                        
                                        ì´ ë¶„ì„ì€ ê° ë³€ìˆ˜ê°€ í˜„ì¬ ì˜ˆì¸¡ì— ì–¼ë§ˆë‚˜ ì˜í–¥ì„ ë¯¸ì¹˜ëŠ”ì§€ ë³´ì—¬ì£¼ëŠ” ì§ê´€ì ì¸ ì§€í‘œì…ë‹ˆë‹¤.
                                        
                                        #### ì‰½ê²Œ ì´í•´í•˜ê¸°
                                        - **ë¹¨ê°„ìƒ‰ ë§‰ëŒ€(ì–‘ìˆ˜)**: ì´ ë³€ìˆ˜ëŠ” ì§€ê¸ˆ ì˜ˆì¸¡ê°’ì„ **ë†’ì´ê³  ìˆì–´ìš”**
                                        - **íŒŒë€ìƒ‰ ë§‰ëŒ€(ìŒìˆ˜)**: ì´ ë³€ìˆ˜ëŠ” ì§€ê¸ˆ ì˜ˆì¸¡ê°’ì„ **ë‚®ì¶”ê³  ìˆì–´ìš”**
                                        - **ë§‰ëŒ€ê°€ ê¸¸ìˆ˜ë¡**: ë³€ìˆ˜ì˜ ì˜í–¥ë ¥ì´ í¬ë‹¤ëŠ” ì˜ë¯¸ì…ë‹ˆë‹¤
                                        
                                        #### ì‹¤ì œ í™œìš©ë²•
                                        - ë¹¨ê°„ìƒ‰(ì–‘ìˆ˜) ë§‰ëŒ€ê°€ í° ë³€ìˆ˜ë¥¼ **ë‚®ì¶”ë©´** â†’ ì˜ˆì¸¡ê°’ì´ ê°ì†Œí•©ë‹ˆë‹¤
                                        - íŒŒë€ìƒ‰(ìŒìˆ˜) ë§‰ëŒ€ê°€ í° ë³€ìˆ˜ë¥¼ **ë‚®ì¶”ë©´** â†’ ì˜ˆì¸¡ê°’ì´ ì¦ê°€í•©ë‹ˆë‹¤
                                        - íŠ¹ì • ëª©í‘œì¹˜ë¥¼ ì›í•œë‹¤ë©´, ë§‰ëŒ€ê°€ í° ë³€ìˆ˜ë¶€í„° ì¡°ì •í•˜ì„¸ìš”
                                        
                                        #### ì˜í–¥ë„ê°€ 0ì¸ ë³€ìˆ˜ëŠ” ì™œ ê·¸ëŸ´ê¹Œìš”?
                                        ì˜í–¥ë„ê°€ 0ìœ¼ë¡œ ë‚˜íƒ€ë‚˜ëŠ” ë³€ìˆ˜ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ì´ìœ ê°€ ìˆìŠµë‹ˆë‹¤:
                                        
                                        1. **í˜„ì¬ ìƒíƒœì—ì„œ ì˜í–¥ì´ ë¯¸ë¯¸í•¨**: ë‹¤ë¥¸ ë³€ìˆ˜ë“¤ì´ ë” ì§€ë°°ì ì¸ ì˜í–¥ì„ ë¯¸ì¹˜ê³  ìˆìŠµë‹ˆë‹¤
                                        2. **ë³€ìˆ˜ì˜ ë²”ìœ„ê°€ ì¢ìŒ**: ìµœì†Œê°’ê³¼ ìµœëŒ€ê°’ ì‚¬ì´ì˜ ì°¨ì´ê°€ ì‘ì•„ì„œ ë³€í™”í•´ë„ ì˜ˆì¸¡ì— í° ì˜í–¥ì´ ì—†ìŠµë‹ˆë‹¤
                                        3. **ëª¨ë¸ì˜ íŠ¹ì„±**: ëª¨ë¸ì´ ì´ ë³€ìˆ˜ì— ëŒ€í•´ í•™ìŠµí•œ ì˜í–¥ë ¥ì´ ì‘ê±°ë‚˜, ë‹¤ë¥¸ ë³€ìˆ˜ì™€ì˜ ìƒí˜¸ì‘ìš©ì—ì„œë§Œ ì¤‘ìš”í•©ë‹ˆë‹¤
                                        4. **ë¹„ì„ í˜• ê´€ê³„**: í˜„ì¬ ê°’ì„ ì¤‘ì‹¬ìœ¼ë¡œëŠ” ì˜í–¥ì´ ì ì§€ë§Œ, ë‹¤ë¥¸ êµ¬ê°„ì—ì„œëŠ” ì˜í–¥ì´ í´ ìˆ˜ ìˆìŠµë‹ˆë‹¤
                                        
                                        > ğŸ’¡ **ì¤‘ìš”**: ì˜í–¥ë„ê°€ 0ì´ë¼ë„ ë°˜ë“œì‹œ ì¤‘ìš”í•˜ì§€ ì•Šì€ ê²ƒì€ ì•„ë‹™ë‹ˆë‹¤! ë‹¤ë¥¸ ìƒí™©ì´ë‚˜ ë‹¤ë¥¸ ë³€ìˆ˜ê°’ê³¼ ì¡°í•©ë  ë•Œ ì¤‘ìš”í•´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
                                        """)
                                else:
                                    st.info("ì˜ˆì¸¡ì„ ë¨¼ì € ìˆ˜í–‰í•´ì£¼ì„¸ìš”.")
                                
                        except Exception as e:
                            import traceback
                            st.error(f"ë³€ìˆ˜ ê¸°ì—¬ë„ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
                            st.code(traceback.format_exc(), language="python")
            else:
                st.info("ë¨¼ì € ëª¨ë¸ì„ í›ˆë ¨í•´ì£¼ì„¸ìš”.")
    else:
        st.error(f"íƒ€ê¹ƒ ë³€ìˆ˜ '{target_col}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
else:
    st.info("ì‹œë®¬ë ˆì´ì…˜ì„ ì‹œì‘í•˜ë ¤ë©´ CSV íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.") 